# ThesisCode
Code for optimal execution

## TODO:
### Agents
- The build model function should probably be broken out of the learning agents
- Add DDQN Agent [TESTING]
	- halve the epsilon decay DONE
- Fix slightly hacky solution to non generalised parameters

### Simulator
- Efficiency
- Robust model saving and figure saving
- Silent training option
- Record model choices for diagnosis
- Remove checks

### Market Models
- Add new market models

### Reading
- Sutton and Barto (p142)
- Next RL execution paper DONE
- Deep L in py book (buy)
- Double deep q paper

#### Other Reading
- Restricted Boltzman machines
- Random Forests
- Target Networks

### Writing
- Talk about DDQN in practise (halving epsilon decay)
- Transformations of the features

### General
- Test training agents with a larger number of options and timesteps
- Find average trade sizes from data
- Initial weights?
- Incorporate changes from the paper (reread)
- Set seed to control reproducability

### Questions for Paul
- The role of gamma in this case? - Risk aversion
- The different approach - estimating action values


