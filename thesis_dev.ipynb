{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/cartpole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for creating directories\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.market_modelsM import market\n",
    "#from library.local_environments import agent_environmentM\n",
    "from library.market_modelsM import bs_stock\n",
    "import library.agents\n",
    "import library.simulations\n",
    "#import library.WIPAgents\n",
    "import library.WIPAgentsv2\n",
    "import library.WIPAgentsv3\n",
    "import library.WIPAgentsv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *market_models* include stock price models and market impact models.\n",
    "- *local_environments* includes agent environments (recording the agents position, cash and market impact, these are built to model AIGym environments\n",
    "- *agents* include market agents, different deepQlearning agents and theoretical baseline agents\n",
    "- *simulator* simplifies the training and evaluation of multiple agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an agent (Fred) who only knows the position and the time. Take the trade options as %s of the total position. For now we assume that he can trade between 1% and 10% at a time (Restrictive - could we make this more flexible?) A uniform partition also doesn't necessarily seem appropriate. Look at continuous generalisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code using new Simulator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload any updated modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'library.WIPAgentsv4' from '/Users/tobyweston/Documents/Imperial/Thesis/ThesisCode/library/WIPAgentsv4.py'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "reload(library.agents)\n",
    "reload(library.simulations)\n",
    "#reload(library.WIPAgents)\n",
    "reload(library.WIPAgentsv2)\n",
    "reload(library.WIPAgentsv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reload() argument must be a module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-ccaa1173b7da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistAgentsWIP2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC51Agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \"\"\"\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \"\"\"\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reload() argument must be a module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reload() argument must be a module"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "reload(library.simulations)\n",
    "reload(library.agents.distAgentsWIP2.C51Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up model identification and differentiation:\n",
    "- Fred: Deep Q Network Model (standard params) \n",
    "- George: Deep Q Network Model (alternative params)\n",
    "- Greg: Deep Q Network Model with Target network\n",
    "- Alice: Double Deep Q Network Model\n",
    "- Rob: Random strategy\n",
    "- Tim: TWAP\n",
    "- David: Distributional RL state action value\n",
    "- Daisy: Distributional RL state value\n",
    "- Paul: Version of Daisy with larger network and 2 epochs of training (how can we use the data more efficiently?)\n",
    "\n",
    "Future:\n",
    "- Harry: Prioritised sweep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ede2287898cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Adj Close.3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m '''\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/EURUSD-2019-01C.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load .csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#appl_data = pd.concat([df1,df2,df3,df4])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# External Packages\n",
    "import numpy as np\n",
    "\n",
    "# Internal Library\n",
    "from library.market_modelsM import market, bs_stock, signal_stock, real_stock\n",
    "from library.agents.distAgentsWIP3 import QRAgent, C51Agent\n",
    "from library.agents.baseAgents import TWAPAgent\n",
    "#from library.agents.distAgents import C51Agent\n",
    "import library.simulations\n",
    "import pandas as pd\n",
    "\n",
    "# Define setup\n",
    "params = {\n",
    "    \"terminal\" : 1,\n",
    "    \"num_trades\" : 10,\n",
    "    \"position\" : 10,\n",
    "    \"batch_size\" : 32,\n",
    "    \"action_values\" : [0.05,0.075,0.09,0.1,0.11,0.15,0.2] #[0.05,0.075,0.1,0.15,0.2] \n",
    "}\n",
    "state_size = 2\n",
    "action_size = len(params[\"action_values\"])\n",
    "n_hist_prices = 32\n",
    "\n",
    "# Define Agents\n",
    "quentin = library.agents.distAgentsWIP3.QRAgent(state_size, params[\"action_values\"], \"Quentin\",C=100, alternative_target = True,UCB=True,UCBc = 100,tree_horizon = 4,market_data_size=n_hist_prices)\n",
    "brian = library.agents.distAgentsWIP3.C51Agent(state_size, params[\"action_values\"], \"Brian Appl 1hr md32\",C=100, alternative_target = True,UCB=True,UCBc = 100,tree_horizon = 4,market_data_size=n_hist_prices)\n",
    "tim = library.agents.baseAgents.TWAPAgent(3,\"TWAP_APPL\", len(params[\"action_values\"]))\n",
    "#print(brian.model.summary())\n",
    "agents = [\n",
    "    quentin\n",
    "]\n",
    "quentin.learning_rate = 0.0005\n",
    "quentin.reward_scaling = True\n",
    "# NOTE: Cosine basis for Isabelle results in a lot of params...\n",
    "\n",
    "# Initialise Simulator\n",
    "# BS market\n",
    "'''\n",
    "simple_stock = bs_stock(1,0,0.0005) # No drift, 0.0005 vol\n",
    "simple_market = market(simple_stock,num_strats = len(agents))\n",
    "my_simulator = library.simulations.simulator(simple_market,agents,params,test_name = \"QR Testing\")\n",
    "'''\n",
    "\n",
    "# real stock testing\n",
    "# Retrieve data\n",
    "'''\n",
    "df1 = pd.read_csv(\"data/2020-05-04SPX_yFinance\",low_memory = False) # Load .csv\n",
    "df1 = df1[\"Adj Close.3\"][2:]\n",
    "df2 = pd.read_csv(\"data/2020-05-16SPX_yFinance\",low_memory = False) # Load .csv\n",
    "df2 = df2[\"Adj Close.3\"][2:]\n",
    "df3 = pd.read_csv(\"data/2020-05-22SPX_yFinance\",low_memory = False) # Load .csv\n",
    "df3 = df3[\"Adj Close.3\"][2:]\n",
    "df4 = pd.read_csv(\"data/2020-05-28SPX_yFinance\",low_memory = False) # Load .csv\n",
    "df4 = df4[\"Adj Close.3\"][2:]\n",
    "'''\n",
    "df = pd.read_csv(\"data/EURUSD-2019-01C.csv\",low_memory = False) # Load .csv\n",
    "\n",
    "#appl_data = pd.concat([df1,df2,df3,df4])\n",
    "print(\"Warning: dropping\",sum(pd.isnull(appl_data)), \"nan value(s)\")\n",
    "appl_data = appl_data.dropna()\n",
    "appl_data = appl_data.values # Extract APPL as np array\n",
    "print(\"Using\",len(appl_data),\"values\")\n",
    "appl_data = appl_data.astype(float) # convert any rogue strings to floats\n",
    "appl_stock = real_stock(appl_data,n_steps = 60,recycle = True,n_train=10) # create stock - traded once per 6 minutes and recycled\n",
    "appl_market = market(appl_stock,n_hist_prices = n_hist_prices)\n",
    "my_simulator = library.simulations.simulator(appl_market,agents,params,test_name = \"Apple Stock Testing\")\n",
    "my_simulator.train(20000)\n",
    "\n",
    "# Signal market\n",
    "'''\n",
    "signal_stock = signal_stock(1,0.0005,0.0005,0.0005) # initial 1, vol 0.0005, signal vol 0.0005, signal reversion 0.0005\n",
    "signal_market = market(signal_stock,num_strats = len(agents))\n",
    "signal_simulator = library.simulations.simulator(signal_market,agents,params,test_name = \"Signal Testing 1\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the agents and Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EURUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.14775]\n",
      " [1.14771]\n",
      " [1.14772]\n",
      " [1.14775]\n",
      " [1.14776]\n",
      " [1.14776]\n",
      " [1.1478 ]\n",
      " [1.1478 ]\n",
      " [1.14779]\n",
      " [1.14779]]\n",
      "Using 1512000 values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tobyg/OptEx\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tobyg/OptEx/runs/2nxttbb3\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx/runs/2nxttbb3</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\")). args: ('https://api.wandb.ai/files/tobyg/OptEx/2nxttbb3/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 25, 'content': ['{\"system.cpu\": 29.96, \"system.memory\": 68.36, \"system.disk\": 52.4, \"system.proc.memory.availableMB\": 2591.98, \"system.proc.memory.rssMB\": 198.1, \"system.proc.memory.percent\": 2.42, \"system.proc.cpu.threads\": 37.0, \"system.network.sent\": 5578752, \"system.network.recv\": 10795008, \"_wandb\": true, \"_timestamp\": 1592832043, \"_runtime\": 802}\\n']}}}}\n",
      "requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\")). args: ('https://api.wandb.ai/files/tobyg/OptEx/2nxttbb3/file_stream',), kwargs: {'json': {'complete': False, 'failed': False}}\n",
      "requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/tobyg/OptEx/2nxttbb3/file_stream (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x19ebeb2e8>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')). args: ('https://api.wandb.ai/files/tobyg/OptEx/2nxttbb3/file_stream',), kwargs: {'json': {'complete': False, 'failed': False}}\n",
      "requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/tobyg/OptEx/2nxttbb3/file_stream (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x19bcd25f8>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')). args: ('https://api.wandb.ai/files/tobyg/OptEx/2nxttbb3/file_stream',), kwargs: {'json': {'complete': False, 'failed': False}}\n",
      "/Users/tobyweston/Applications/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.183548). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3ba3f15b66cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mappl_market\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mmy_simulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappl_market\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"EURUSD Testing by second\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Signal market\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0;31m#self._pretrain_position()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensive_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self, verbose, evaluate)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                 \u001b[0;31m# Agents action only updated if still active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                                         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# Could speed up (only need to change once)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                 \u001b[0;31m#print(\"var\",self.variance(state))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0;31m#print(\"act_values\",act_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                 \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mct\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                                 \u001b[0;31m#print(\"Act\",act)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mvariance\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;31m#print(\"00\",np.power(self.predict_action(state,0,above_med = self.optimisticUCB),2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabove_med\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisticUCB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_action\u001b[0;34m(self, state, action_index, target, above_med)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m#print(\"state action\",state_action,\"embedded_quantiles\",self.embedded_quantiles)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m#print(self.model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_quantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;31m#if self.C > 0 and target:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                         \u001b[0;31m#assert not above_med, \"Why is variance being used with target?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_quantiles\u001b[0;34m(self, state_action, target)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Sample-based predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_end\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# External Packages\n",
    "import numpy as np\n",
    "\n",
    "# Internal Library\n",
    "from library.market_modelsM import market, bs_stock, signal_stock, real_stock\n",
    "from library.agents.distAgentsWIP2 import QRAgent, C51Agent\n",
    "from library.agents.baseAgents import TWAPAgent\n",
    "#from library.agents.distAgents import C51Agent\n",
    "import library.simulations\n",
    "import pandas as pd\n",
    "\n",
    "# Define setup\n",
    "params = {\n",
    "    \"terminal\" : 1,\n",
    "    \"num_trades\" : 600,\n",
    "    \"position\" : 10,\n",
    "    \"batch_size\" : 32,\n",
    "    \"action_values\" : [0.5,0.98,0.99,0.998,1.0,1.002,1.01,1.02,1.5] #[0.05,0.075,0.09,0.1,0.11,0.15,0.2] #[0.05,0.075,0.1,0.15,0.2] \n",
    "}\n",
    "\n",
    "state_size = 2\n",
    "action_size = len(params[\"action_values\"])\n",
    "n_hist_prices = 32\n",
    "\n",
    "# Define Agents\n",
    "quentin = library.agents.distAgentsWIP2.QRAgent(state_size, params[\"action_values\"], \"Quentin tr600\",C=100, alternative_target = True,UCB=True,UCBc = 250,tree_horizon = 40,market_data_size=n_hist_prices)\n",
    "#brian = library.agents.distAgentsWIP3.C51Agent(state_size, params[\"action_values\"], \"Brian Appl 1hr md32\",C=100, alternative_target = True,UCB=True,UCBc = 100,tree_horizon = 4,market_data_size=n_hist_prices)\n",
    "tim = library.agents.baseAgents.TWAPAgent(params[\"action_values\"].index(1.0),\"TWAP_EURUSD tr600\", len(params[\"action_values\"]))\n",
    "#print(brian.model.summary())\n",
    "agents = [\n",
    "    quentin\n",
    "]\n",
    "quentin.learning_rate = 0.000025\n",
    "quentin.reward_scaling = True\n",
    "quentin.epsilon_min = 0.05\n",
    "\n",
    "# NOTE: Cosine basis for Isabelle results in a lot of params...\n",
    "\n",
    "# Initialise Simulator\n",
    "# BS market\n",
    "\n",
    "df = pd.read_csv(\"data/EURUSD-2019-01C.csv\",low_memory = False, names=[\"Instrument\", \"Time\", \"Bid\", \"Ask\"]) # Load .csv\n",
    "df = df[\"Bid\"]\n",
    "\n",
    "# Instead use the processed by the second data\n",
    "df = df_cut\n",
    "\n",
    "#print(\"Warning: dropping\",sum(pd.isnull(df)), \"nan value(s)\")\n",
    "\n",
    "#appl_data = appl_data.dropna()\n",
    "appl_data = df.values # Extract APPL as np array\n",
    "print(appl_data[:10])\n",
    "print(\"Using\",len(appl_data),\"values\")\n",
    "appl_data = appl_data.astype(float) # convert any rogue strings to floats\n",
    "appl_stock = real_stock(appl_data,n_steps = params[\"num_trades\"],recycle = True,n_train=1000) # create stock - traded once per 6 minutes and recycled\n",
    "appl_market = market(appl_stock,n_hist_prices = n_hist_prices)\n",
    "### Micro intervals ###\n",
    "# Assume we are executing over 10s intervals, k should therefore be 600 times smaller (both vol and time / 600 but vol appears twice)\n",
    "\n",
    "# Now executing over 40s intervals\n",
    "appl_market.k /= 60\n",
    "my_simulator = library.simulations.simulator(appl_market,agents,params,test_name = \"EURUSD Testing by second\")\n",
    "my_simulator.train(30000)\n",
    "\n",
    "# Signal market\n",
    "'''\n",
    "signal_stock = signal_stock(1,0.0005,0.0005,0.0005) # initial 1, vol 0.0005, signal vol 0.0005, signal reversion 0.0005\n",
    "signal_market = market(signal_stock,num_strats = len(agents))\n",
    "signal_simulator = library.simulations.simulator(signal_market,agents,params,test_name = \"Signal Testing 1\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "my_simulator.train(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quentin.stock_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "      <th>bid</th>\n",
       "      <th>bidSize</th>\n",
       "      <th>ask</th>\n",
       "      <th>askSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 days 00:00:05.727000000</td>\n",
       "      <td>7258.5</td>\n",
       "      <td>68371.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>485885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:00:05.759000000</td>\n",
       "      <td>7258.5</td>\n",
       "      <td>68371.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>484842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0 days 00:00:05.764000000</td>\n",
       "      <td>7258.5</td>\n",
       "      <td>68371.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>483894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0 days 00:00:05.769000000</td>\n",
       "      <td>7258.5</td>\n",
       "      <td>68371.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>484864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0 days 00:00:05.796000000</td>\n",
       "      <td>7258.5</td>\n",
       "      <td>68371.0</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>479864.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       time     bid  bidSize     ask   askSize\n",
       "0      0  0 days 00:00:05.727000000  7258.5  68371.0  7259.0  485885.0\n",
       "1      1  0 days 00:00:05.759000000  7258.5  68371.0  7259.0  484842.0\n",
       "2      2  0 days 00:00:05.764000000  7258.5  68371.0  7259.0  483894.0\n",
       "3      3  0 days 00:00:05.769000000  7258.5  68371.0  7259.0  484864.0\n",
       "4      4  0 days 00:00:05.796000000  7258.5  68371.0  7259.0  479864.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/2019_05_19BTX_O.csv\",low_memory = False) # Load .csv\n",
    "df.columns = [\"index\",\"time\",\"bid\",\"bidSize\",\"ask\",\"askSize\"]\n",
    "df.head()\n",
    "#diff = df[\"Time\"][1] - df[\"Time\"][0] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change index to the time and group data by the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190101 22:06:11.699\n",
      "2019-01-01 22:06:11\n",
      "                        Instrument      Bid      Ask\n",
      "Time                                                \n",
      "2019-01-01 22:06:11.699    EUR/USD  1.14587  1.14727\n",
      "2019-01-01 22:06:12.634    EUR/USD  1.14567  1.14707\n",
      "2019-01-01 22:06:13.091    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:20.566    EUR/USD  1.14574  1.14713\n",
      "2019-01-01 22:06:20.573    EUR/USD  1.14589  1.14730\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "print(df[\"Time\"][0])\n",
    "print(datetime.strptime('20190101 22:06:11','%Y%m%d %H:%M:%S'))\n",
    "df[\"Time\"] =  pd.to_datetime(df['Time'], format='%Y%m%d %H:%M:%S.%f')\n",
    "#print(df[\"Time\"][:50]-df[\"Time\"][:50].shift(1))\n",
    "\n",
    "#df[\"fTime\"] = df[\"Time\"].dt.strftime('%H:%M:%S')\n",
    "#df[\"Day\"] = df[\"Time\"].dt.strftime('%d')\n",
    "df = df.set_index(\"Time\")\n",
    "# Try translating dataset to by the half second between 6am and 8pm\n",
    "print(df.head())\n",
    "grouped = df.groupby([pd.Grouper(freq='S')])\n",
    "result = grouped.last()\n",
    "# Need to add a count here eventually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Instrument      Bid      Ask\n",
      "Time                                            \n",
      "2019-01-01 22:06:11    EUR/USD  1.14587  1.14727\n",
      "2019-01-01 22:06:12    EUR/USD  1.14567  1.14707\n",
      "2019-01-01 22:06:13    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:14    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:15    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:16    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:17    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:18    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:19    EUR/USD  1.14507  1.14647\n",
      "2019-01-01 22:06:20    EUR/USD  1.14589  1.14730\n"
     ]
    }
   ],
   "source": [
    "# Replace all NA values with the previous price\n",
    "result = result.fillna(method='ffill')\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Bid\n",
      "Time                        \n",
      "2019-01-02 06:00:00  1.14775\n",
      "2019-01-02 06:00:01  1.14771\n",
      "2019-01-02 06:00:02  1.14772\n",
      "2019-01-02 06:00:03  1.14775\n",
      "2019-01-02 06:00:04  1.14776\n",
      "2019-01-02 06:00:05  1.14776\n",
      "2019-01-02 06:00:06  1.14780\n",
      "2019-01-02 06:00:07  1.14780\n",
      "2019-01-02 06:00:08  1.14779\n",
      "2019-01-02 06:00:09  1.14779\n"
     ]
    }
   ],
   "source": [
    "# Cut out of hours (In this case before 6am and after 8pm)\n",
    "df_cut = result.loc[pd.to_numeric(result.index.strftime('%H')) > 5] \n",
    "df_cut = df_cut.loc[pd.to_numeric(df_cut.index.strftime('%H')) < 20] \n",
    "#print(pd.to_numeric(df[\"Time\"].dt.strftime('%H'))[:10])\n",
    "# Cut extrenous columns\n",
    "df_cut = df_cut[['Bid']]\n",
    "\n",
    "# Aggregate by the second retaining number of price updates and the last updated price\n",
    "#proc_prices = (df_cut.groupby(['Day','fTime']).agg([('count','count'),('bid','last')]).reset_index())\n",
    "#df_cut = df_cut.set_index(['Day','fTime'])\n",
    "\n",
    "print(df_cut[:10])\n",
    "# proc_prices = proc_prices.set_index(['Day','fTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BTX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                       time     bid  bidSize     ask   askSize\n",
      "0      0  0 days 00:00:05.727000000  7258.5  68371.0  7259.0  485885.0\n",
      "1      1  0 days 00:00:05.759000000  7258.5  68371.0  7259.0  484842.0\n",
      "2      2  0 days 00:00:05.764000000  7258.5  68371.0  7259.0  483894.0\n",
      "3      3  0 days 00:00:05.769000000  7258.5  68371.0  7259.0  484864.0\n",
      "4      4  0 days 00:00:05.796000000  7258.5  68371.0  7259.0  479864.0\n",
      "   Unnamed: 0                       time     side     size   price\n",
      "0           0  0 days 00:00:05.888000000  b'Sell'  15945.0  7258.5\n",
      "1           1  0 days 00:00:05.899000000  b'Sell'    238.0  7257.5\n",
      "2           2  0 days 00:00:05.899000000  b'Sell'    238.0  7257.5\n",
      "3           3  0 days 00:00:05.899000000  b'Sell'    238.0  7257.5\n",
      "4           4  0 days 00:00:05.899000000  b'Sell'    238.0  7257.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/2019_05_19BTX_O.csv\",low_memory = False) # Load .csv\n",
    "df.columns = [\"index\",\"time\",\"bid\",\"bidSize\",\"ask\",\"askSize\"]\n",
    "df_trades = pd.read_csv(\"data/2019_05_19BTX_T.csv\",low_memory = False) # Load .csv\n",
    "print(df.head())\n",
    "print(df_trades.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim, rename cols and remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        time     bid  bidSize     ask   askSize\n",
      "0  0 days 00:00:05.727000000  7258.5  68371.0  7259.0  485885.0\n",
      "1  0 days 00:00:05.759000000  7258.5  68371.0  7259.0  484842.0\n",
      "2  0 days 00:00:05.764000000  7258.5  68371.0  7259.0  483894.0\n",
      "3  0 days 00:00:05.769000000  7258.5  68371.0  7259.0  484864.0\n",
      "4  0 days 00:00:05.796000000  7258.5  68371.0  7259.0  479864.0\n",
      "                         time     side     size   price\n",
      "0   0 days 00:00:05.888000000  b'Sell'  15945.0  7258.5\n",
      "1   0 days 00:00:05.899000000  b'Sell'    238.0  7257.5\n",
      "8   0 days 00:00:06.478000000  b'Sell'   1915.0  7257.5\n",
      "9   0 days 00:00:06.762000000  b'Sell'   7400.0  7257.5\n",
      "10  0 days 00:00:06.868000000  b'Sell'     50.0  7257.5\n"
     ]
    }
   ],
   "source": [
    "df = df[[\"time\",\"bid\",\"bidSize\",\"ask\",\"askSize\"]]\n",
    "df_trades.columns = [\"index\",\"time\",\"side\",\"size\",\"price\"]\n",
    "df_trades = df_trades[[\"time\",\"side\",\"size\",\"price\"]]\n",
    "df = df.drop_duplicates()\n",
    "df_trades = df_trades.drop_duplicates()\n",
    "print(df.head())\n",
    "print(df_trades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat times and reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            bid  bidSize     ask   askSize\n",
      "time                                                      \n",
      "1900-01-01 00:00:05.727  7258.5  68371.0  7259.0  485885.0\n",
      "1900-01-01 00:00:05.759  7258.5  68371.0  7259.0  484842.0\n",
      "1900-01-01 00:00:05.764  7258.5  68371.0  7259.0  483894.0\n",
      "1900-01-01 00:00:05.769  7258.5  68371.0  7259.0  484864.0\n",
      "1900-01-01 00:00:05.796  7258.5  68371.0  7259.0  479864.0\n",
      "                            side     size   price\n",
      "time                                             \n",
      "1900-01-01 00:00:05.888  b'Sell'  15945.0  7258.5\n",
      "1900-01-01 00:00:05.899  b'Sell'    238.0  7257.5\n",
      "1900-01-01 00:00:06.478  b'Sell'   1915.0  7257.5\n",
      "1900-01-01 00:00:06.762  b'Sell'   7400.0  7257.5\n",
      "1900-01-01 00:00:06.868  b'Sell'     50.0  7257.5\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df['time'], format='0 days %H:%M:%S.%f')\n",
    "df_trades[\"time\"] = pd.to_datetime(df_trades['time'], format='0 days %H:%M:%S.%f')\n",
    "df = df.set_index(\"time\")\n",
    "df_trades = df_trades.set_index(\"time\")\n",
    "print(df.head())\n",
    "print(df_trades.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            side     size   price\n",
      "time                                             \n",
      "1900-01-01 00:00:05.888  b'Sell'  15945.0  7258.5\n",
      "1900-01-01 00:00:05.899  b'Sell'    238.0  7257.5\n",
      "1900-01-01 00:00:06.478  b'Sell'   1915.0  7257.5\n",
      "1900-01-01 00:00:06.762  b'Sell'   7400.0  7257.5\n",
      "1900-01-01 00:00:06.868  b'Sell'     50.0  7257.5\n",
      "1900-01-01 00:00:06.894   b'Buy'     30.0  7258.0\n",
      "1900-01-01 00:00:06.952  b'Sell'    500.0  7257.5\n",
      "1900-01-01 00:00:07.074   b'Buy'   1000.0  7257.5\n",
      "1900-01-01 00:00:07.097   b'Buy'    304.0  7258.0\n",
      "1900-01-01 00:00:07.226  b'Sell'   7051.0  7256.0\n",
      "1900-01-01 00:00:07.256   b'Buy'   8384.0  7257.5\n",
      "1900-01-01 00:00:07.305  b'Sell'   2000.0  7256.0\n",
      "1900-01-01 00:00:09.709  b'Sell'      5.0  7256.0\n",
      "1900-01-01 00:00:10.712  b'Sell'    500.0  7256.0\n",
      "1900-01-01 00:00:11.045  b'Sell'     10.0  7256.0\n",
      "1900-01-01 00:00:11.390  b'Sell'    430.0  7256.0\n",
      "1900-01-01 00:00:11.772   b'Buy'     50.0  7256.5\n",
      "1900-01-01 00:00:11.992  b'Sell'   4279.0  7256.0\n",
      "1900-01-01 00:00:12.309  b'Sell'    170.0  7256.0\n",
      "1900-01-01 00:00:12.590  b'Sell'      1.0  7256.0\n",
      "1900-01-01 00:00:12.717   b'Buy'    929.0  7256.5\n",
      "1900-01-01 00:00:12.768   b'Buy'      2.0  7256.5\n",
      "1900-01-01 00:00:12.808   b'Buy'    290.0  7256.5\n",
      "1900-01-01 00:00:12.929  b'Sell'    351.0  7255.0\n",
      "1900-01-01 00:00:13.106  b'Sell'    100.0  7255.0\n",
      "1900-01-01 00:00:13.144   b'Buy'      1.0  7255.5\n",
      "1900-01-01 00:00:13.391  b'Sell'   5000.0  7255.0\n",
      "1900-01-01 00:00:13.517  b'Sell'   5000.0  7255.0\n",
      "1900-01-01 00:00:14.100  b'Sell'      5.0  7255.0\n",
      "1900-01-01 00:00:14.668  b'Sell'   3200.0  7255.0\n"
     ]
    }
   ],
   "source": [
    "print(df_trades[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trades[\"side\"] = df_trades[\"side\"].astype(str)\n",
    "\n",
    "#print(df_trades[df_trades[\"side\"] == \"b'Sell'\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            bid  bidSize     ask   askSize\n",
      "time                                                      \n",
      "1900-01-01 00:00:05.727  7258.5  68371.0  7259.0  485885.0\n",
      "1900-01-01 00:00:05.759  7258.5  68371.0  7259.0  484842.0\n",
      "1900-01-01 00:00:05.764  7258.5  68371.0  7259.0  483894.0\n",
      "1900-01-01 00:00:05.769  7258.5  68371.0  7259.0  484864.0\n",
      "1900-01-01 00:00:05.796  7258.5  68371.0  7259.0  479864.0\n",
      "1900-01-01 00:00:05.797  7258.5  68371.0  7259.0  469864.0\n",
      "1900-01-01 00:00:05.798  7258.5  68371.0  7259.0  463864.0\n",
      "1900-01-01 00:00:05.800  7258.5  68371.0  7259.0  457864.0\n",
      "1900-01-01 00:00:05.805  7258.5  68371.0  7259.0  447864.0\n",
      "1900-01-01 00:00:05.832  7258.5  68371.0  7259.0  447281.0\n",
      "1900-01-01 00:00:05.887  7258.5  68371.0  7259.0  437281.0\n",
      "1900-01-01 00:00:05.888  7258.5  18371.0  7259.0  487281.0\n",
      "1900-01-01 00:00:05.899  7257.5  11812.0  7259.0  487281.0\n",
      "1900-01-01 00:00:05.937  7257.5  11812.0  7258.0     970.0\n",
      "1900-01-01 00:00:05.941  7257.5  11812.0  7258.0    9532.0\n",
      "1900-01-01 00:00:05.960  7257.5  11812.0  7258.0   99557.0\n",
      "1900-01-01 00:00:05.974  7257.5  11812.0  7258.0  107465.0\n",
      "1900-01-01 00:00:05.978  7257.5  11812.0  7258.0  114900.0\n",
      "1900-01-01 00:00:05.982  7257.5  11812.0  7258.0  147966.0\n",
      "1900-01-01 00:00:05.996  7257.5  11812.0  7258.0  156965.0\n",
      "1900-01-01 00:00:06.133  7257.5  11812.0  7258.0  157065.0\n",
      "1900-01-01 00:00:06.134  7257.5  11812.0  7258.0  157165.0\n",
      "1900-01-01 00:00:06.136  7257.5  11812.0  7258.0  158210.0\n",
      "1900-01-01 00:00:06.405  7257.5  11812.0  7258.0  165564.0\n",
      "1900-01-01 00:00:06.413  7257.5  11812.0  7258.0  177564.0\n",
      "                            side     size   price\n",
      "time                                             \n",
      "1900-01-01 00:00:05.888  b'Sell'  15945.0  7258.5\n",
      "1900-01-01 00:00:05.899  b'Sell'    238.0  7257.5\n",
      "1900-01-01 00:00:06.478  b'Sell'   1915.0  7257.5\n",
      "1900-01-01 00:00:06.762  b'Sell'   7400.0  7257.5\n",
      "1900-01-01 00:00:06.868  b'Sell'     50.0  7257.5\n",
      "                        bid  bidSize     ask   askSize\n",
      "time                                                  \n",
      "1900-01-01 00:00:05  7257.5  11812.0  7258.0  156965.0\n",
      "1900-01-01 00:00:06  7257.0   1888.0  7257.5   12164.0\n",
      "1900-01-01 00:00:07  7256.0  26954.0  7257.5  164525.0\n",
      "1900-01-01 00:00:08     NaN      NaN     NaN       NaN\n",
      "1900-01-01 00:00:09  7256.0  26949.0  7256.5   91250.0\n",
      "                       size    price\n",
      "time                                \n",
      "1900-01-01 00:00:06    30.0   7258.0\n",
      "1900-01-01 00:00:07  9688.0  21773.0\n",
      "1900-01-01 00:00:08     0.0      0.0\n",
      "1900-01-01 00:00:09     0.0      0.0\n",
      "1900-01-01 00:00:10     0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "df_trades[\"side\"] = df_trades[\"side\"].astype(str)\n",
    "df_trades_B = df_trades[df_trades[\"side\"] == \"b'Buy'\"]\n",
    "grouped = df.groupby([pd.Grouper(freq='S')])\n",
    "result = grouped.last()\n",
    "grouped_t = df_trades_B.groupby([pd.Grouper(freq='S')])\n",
    "result_t = grouped_t.sum()\n",
    "print(df[:25])\n",
    "print(df_trades.head())\n",
    "print(result.head())\n",
    "print(result_t.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bid  bidSize     ask   askSize\n",
      "time                                                  \n",
      "1900-01-01 00:00:05  7257.5  11812.0  7258.0  156965.0\n",
      "1900-01-01 00:00:06  7257.0   1888.0  7257.5   12164.0\n",
      "1900-01-01 00:00:07  7256.0  26954.0  7257.5  164525.0\n",
      "1900-01-01 00:00:08  7256.0  26954.0  7257.5  164525.0\n",
      "1900-01-01 00:00:09  7256.0  26949.0  7256.5   91250.0\n",
      "                       size    price\n",
      "time                                \n",
      "1900-01-01 00:00:06    30.0   7258.0\n",
      "1900-01-01 00:00:07  9688.0  21773.0\n",
      "1900-01-01 00:00:08     0.0      0.0\n",
      "1900-01-01 00:00:09     0.0      0.0\n",
      "1900-01-01 00:00:10     0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "result = result.fillna(method='ffill')\n",
    "result_t = result_t.fillna(method='ffill')\n",
    "print(result.head())\n",
    "print(result_t.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bid  bidSize     ask   askSize   buyMO\n",
      "time                                                          \n",
      "1900-01-01 00:00:06  7257.0   1888.0  7257.5   12164.0    30.0\n",
      "1900-01-01 00:00:07  7256.0  26954.0  7257.5  164525.0  9688.0\n",
      "1900-01-01 00:00:08  7256.0  26954.0  7257.5  164525.0     0.0\n",
      "1900-01-01 00:00:09  7256.0  26949.0  7256.5   91250.0     0.0\n",
      "1900-01-01 00:00:10  7256.0  46404.0  7256.5  123848.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Get rid of price from trades\n",
    "result_t_S = result_t[[\"size\"]]\n",
    "merged = pd.concat([result,result_t_S],axis=1,join=\"inner\")\n",
    "#result.merge(result_t_S, how = \"left\")\n",
    "merged.columns = [\"bid\",\"bidSize\",\"ask\",\"askSize\",\"buyMO\"]\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BTX Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'library.market_modelsM.real_stock_lob'>\n",
      "LOs capped at 10\n"
     ]
    }
   ],
   "source": [
    "import library.market_modelsM\n",
    "from imp import reload\n",
    "reload(library.market_modelsM)\n",
    "stock = library.market_modelsM.real_stock_lob(merged)\n",
    "market = library.market_modelsM.lob_market(stock,4)\n",
    "#env = library.local_environments.orderbook_environment(market,10,10,[0,0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[659856.] 659860.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#market.reset()\n",
    "market.place_limit_order(4)\n",
    "#market.progress(0.1)\n",
    "#market.place_limit_order(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[659856.]\n"
     ]
    }
   ],
   "source": [
    "print(market.lo_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size [4.] pos_lt [False] pos [634856.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market.execute_lob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: W&B is disabled in this directory.  Run `wandb on` to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'library.market_modelsM.real_stock_lob'>\n",
      "LOs capped at 10\n",
      "done\n",
      "Using orderbook environment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size [] pos_lt [] pos []\n",
      "[254221.] 254231.0\n",
      "size [10.] pos_lt [False] pos [215907.]\n",
      "size [10.] pos_lt [False] pos [215906.]\n",
      "size [10.] pos_lt [False] pos [211256.]\n",
      "size [10.] pos_lt [False] pos [211256.]\n",
      "size [10.] pos_lt [False] pos [106622.]\n",
      "size [10.] pos_lt [False] pos [97005.]\n",
      "size [10.] pos_lt [False] pos [97005.]\n",
      "size [10.] pos_lt [False] pos [95224.]\n",
      "size [10.] pos_lt [False] pos [95224.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-33c4d715850f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmy_simulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Orderbook Testing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morderbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0;31m#self._pretrain_position()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensive_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mepisode\u001b[0;34m(self, verbose, evaluate)\u001b[0m\n\u001b[1;32m    286\u001b[0m                                         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# Could speed up (only need to change once)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_agents\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"multiple agents not supported\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/local_environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/local_environments.py\u001b[0m in \u001b[0;36msell\u001b[0;34m(self, volume)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mdelta_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# ... then execute any market orders ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mcapped_mo_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcapped_mo_volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mreturns\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapped_mo_volume\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "import library.agents.distAgentsWIP2, library.simulations\n",
    "reload(library.agents.distAgentsWIP2)\n",
    "reload(library.simulations)\n",
    "\n",
    "params = {\n",
    "    \"terminal\" : 1,\n",
    "    \"num_trades\" : 10,\n",
    "    \"position\" : 100000,\n",
    "    \"batch_size\" : 32,\n",
    "    \"action_values\" : [[0.99,0],[1,0],[1.01,0],\n",
    "                       [0.495,0.495],[0.5,0.5],[0.505,0.505],\n",
    "                       [0,0.99],[0,1],[0,1.01]] # [0.001,0.005,0.01,0.015,0.02,0.03,0.05,0.075,0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "}\n",
    "state_size = 7\n",
    "harry = library.agents.distAgentsWIP2.QRAgent(state_size, params[\"action_values\"], \"Harry\",C=100, alternative_target = True,UCB=True,UCBc = 200,tree_horizon = 3,orderbook =True)#,market_data_size=n_hist_prices)\n",
    "\n",
    "agents = [\n",
    "    harry\n",
    "]\n",
    "\n",
    "stock = library.market_modelsM.real_stock_lob(merged)\n",
    "market = library.market_modelsM.lob_market(stock,0)\n",
    "test_env = library.local_environments.orderbook_environment(market,params[\"position\"],params[\"num_trades\"],params[\"action_values\"])\n",
    "print(\"done\")\n",
    "my_simulator = library.simulations.simulator(market,agents,params,test_name = \"Orderbook Testing\",orderbook = True)\n",
    "my_simulator.train(500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tobyg/OptEx\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tobyg/OptEx/runs/25p8o2iw\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx/runs/25p8o2iw</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e2b306635c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mmy_simulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_market\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test 28\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#my_simulator.plot_title = \"Test 20\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update target network if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/baseAgents.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmem_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                         \u001b[0;31m#print(\"replay state\",state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, state, action_index, reward, next_state, done, mem_index)\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;31m#print(\"predictions\",self.predict(next_state,quantiles_selected = quantiles_selected))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m                 \u001b[0;31m#print(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                         \u001b[0mnext_action_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mhorizon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmem_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state, target)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_action\u001b[0;34m(self, state, action_index, target, above_med)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m#print(\"state action\",state_action,\"embedded_quantiles\",self.embedded_quantiles)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m#print(self.model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_quantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;31m#if self.C > 0 and target:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                         \u001b[0;31m#assert not above_med, \"Why is variance being used with target?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_quantiles\u001b[0;34m(self, state_action, target)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           outputs = execute.execute(\n\u001b[0;32m--> 594\u001b[0;31m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# External Packages\n",
    "import numpy as np\n",
    "\n",
    "# Internal Library\n",
    "from library.market_modelsM import market, bs_stock, signal_stock, real_stock\n",
    "from library.agents.distAgentsWIP2 import QRAgent, C51Agent\n",
    "from library.agents.baseAgents import TWAPAgent\n",
    "from library.agents.valueAgents import DDQNAgent\n",
    "#from library.agents.distAgents import C51Agent\n",
    "import library.simulations\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"terminal\" : 1,\n",
    "    \"num_trades\" : 10,\n",
    "    \"position\" : 10,\n",
    "    \"batch_size\" : 32,\n",
    "    \"action_values\" : [0.05,0.075,0.1,0.15,0.2] # [0.001,0.005,0.01,0.015,0.02,0.03,0.05,0.075,0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "}\n",
    "# Optimal action 0.1\n",
    "state_size = 2\n",
    "action_size = len(params[\"action_values\"])\n",
    "\n",
    "#fred = library.agents.DQNAgent(state_size, action_size,\"Fred\") # initialise agent\n",
    "#greg = library.agents.DQNAgent(state_size, action_size,\"Greg15\",C=15) # Second agent\n",
    "#greta = library.agents.DQNAgent(state_size, action_size,\"Greta4\",C=4,alternative_target = True) # Second agent\n",
    "\n",
    "#alice = library.agents.DDQNAgent(state_size, action_size,\"Alice\")\n",
    "#alice2 = library.agents.DDQNAgent(state_size, action_size,\"Alice2\")\n",
    "\n",
    "#tim = library.agents.baseAgents.TWAPAgent(2,\"Tim\")\n",
    "#rob = library.agents.randomAgent(4,\"Rob\",action_size = action_size)\n",
    "\n",
    "#amanda = library.agents.DDQNAgent(state_size, action_size,\"Amanda30\",C=30) # Second agent\n",
    "#agnes = library.agents.DDQNAgent(state_size, action_size,\"Agnes10\",C=10,alternative_target = True) # Second agent\n",
    "\n",
    "#daisy8a = library.WIPAgentsv2.distAgent(action_size,\"Daisy8 Alt\",C=8,alternative_target = True)\n",
    "#daisy8a2 = library.WIPAgentsv2.distAgent(\"Daisy8 Alt 2\",C=8,alternative_target = True)\n",
    "#amanda10a = library.agents.DDQNAgent(state_size, action_size,\"Amanda50 Alt\",C=50)\n",
    "#amanda20 = library.agents.DDQNAgent(state_size, action_size,\"Amanda20\",C=20) \n",
    "#greta = library.agents.DQNAgent(state_size, action_size,\"Greta4\",C=4,alternative_target = True)\n",
    "#paul8a = library.WIPAgentsv3.distAgentL(\"Paul\",C=8,alternative_target = True)\n",
    "#daisy100N51 = library.WIPAgentsv2.distAgent(action_size,\"Daisy100 N51\",N=51,C=100,alternative_target = False)\n",
    "#daisy15aN21 = library.WIPAgentsv2.distAgent(action_size,\"Daisy15 Alt N21\",N=21,C=15,alternative_target = True)\n",
    "\n",
    "#daisy15N11 = library.WIPAgentsv2.distAgent(action_size,\"Daisy15 N11\",N=11,C=15,alternative_target = False,UCB = False)\n",
    "\n",
    "#daisy25aN31_geo10k = library.WIPAgentsv2.distAgent(action_size,\"Daisy25 Alt N31\",N=31,C=25,alternative_target = True)\n",
    "#daisy25aN31_9995 = library.WIPAgentsv2.distAgent(action_size,\"Daisy25 Alt N31\",N=31,C=25,alternative_target = True)\n",
    "#daisy25aN31_9999 = library.WIPAgentsv2.distAgent(action_size,\"Daisy25 Alt N31\",N=31,C=25,alternative_target = True)\n",
    "#daisy25aN31_99995 = library.WIPAgentsv2.distAgent(action_size,\"Daisy25 Alt N31\",N=31,C=25,alternative_target = True)\n",
    "\n",
    "#candidate1 = library.WIPAgentsv2.distAgent(action_size,\"Daisy400a N31 UCB80 n4\",N=31,C=400,alternative_target = True,UCB = True, UCBc = 80)\n",
    "#candidate2 = library.WIPAgentsv2.distAgent(action_size,\"Daisy150a N41 UCB100 n4\",N=41,C=150,alternative_target = True,UCB = True,UCBc = 100)\n",
    "#brian = library.agents.distAgentsWIP2.C51Agent(state_size, params[\"action_values\"],\"BrianOg100a N41 UCB100 n4\",N=41,C=100,alternative_target = True,UCB = True,UCBc = 90)\n",
    "\n",
    "quentin = library.agents.distAgentsWIP2.QRAgent(state_size, params[\"action_values\"], \"Quentin No MD\",C=100, alternative_target = True,UCB=True,UCBc = 200,tree_horizon = 3)#,market_data_size=n_hist_prices)\n",
    "quentin_eps = library.agents.distAgentsWIP2.QRAgent(state_size, params[\"action_values\"], \"Quentin No MD eps\",C=100, alternative_target = True,UCB=False,UCBc = 0,tree_horizon = 3)#,market_data_size=n_hist_prices)\n",
    "#amanda = library.agents.valueAgents.DDQNAgent(state_size, action_size,\"Amanda200\",C=200,alternative_target = True) \n",
    "\n",
    "agents = [\n",
    "    quentin\n",
    "]\n",
    "quentin.learning_rate = 0.001\n",
    "\n",
    "#amanda10a.tree_n = 4\n",
    "#candidate1.tree_n = 5\n",
    "#brian.tree_n = 4\n",
    "\n",
    "\n",
    "#daisy8a2.epsilon_min = 0.1\n",
    "#paul8a.epsilon_min = 0.04\n",
    "#amanda10a.epsilon_min = 0.01\n",
    "#alice.learning_rate = 0.01\n",
    "\n",
    "simple_stock = bs_stock(1,0,0.0005) # No drift, 0.0005 vol\n",
    "simple_market = market(simple_stock)\n",
    "\n",
    "epsilon_decays = [0.99992,0.9995,0.9999,0.99995,1]\n",
    "\n",
    "my_simulator = library.simulations.simulator(simple_market,agents,params,test_name = \"Test 28\")\n",
    "#my_simulator.plot_title = \"Test 20\"\n",
    "my_simulator.train(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4858236  0.4854226  0.48502162 0.48421964 0.48341766]]\n",
      "[[0.504161   0.49303353 0.4881711  0.4863795  0.48419216 0.4819001\n",
      "  0.47893927 0.47543344 0.46721983]]\n",
      "[[0.5063431  0.4952353  0.49020696 0.48772845 0.48581648 0.48335174\n",
      "  0.4806112  0.47624958 0.46686953]]\n"
     ]
    }
   ],
   "source": [
    "print(quentin.predict([[0,0]]))\n",
    "print(quentin.predict_quantiles([[0,0]],4,target = True))\n",
    "print(quentin.predict_quantiles([[0,0]],0,target = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/2020_05_04_SPX_yFinance' does not exist: b'data/2020_05_04_SPX_yFinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-57397f6d7739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Retrieve data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/2020_05_04_SPX_yFinance\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load .csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Adj Close.3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/2020_05_16_SPX_yFinance\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load .csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/2020_05_04_SPX_yFinance' does not exist: b'data/2020_05_04_SPX_yFinance'"
     ]
    }
   ],
   "source": [
    "# External Packages\n",
    "import numpy as np\n",
    "\n",
    "# Internal Library\n",
    "from library.market_modelsM import market, bs_stock, signal_stock, real_stock\n",
    "from library.agents.distAgentsWIP2 import QRAgent, C51Agent\n",
    "from library.agents.baseAgents import TWAPAgent\n",
    "#from library.agents.distAgents import C51Agent\n",
    "import library.simulations\n",
    "import pandas as pd\n",
    "\n",
    "# Define setup\n",
    "params = {\n",
    "    \"terminal\" : 3600,\n",
    "    \"num_trades\" : 10,\n",
    "    \"position\" : 1,\n",
    "    \"batch_size\" : 32,\n",
    "    \"action_values\" : [0.05,0.075,0.09,0.1,0.11,0.15,0.2] #[0.05,0.075,0.1,0.15,0.2] \n",
    "}\n",
    "state_size = 2\n",
    "action_size = len(params[\"action_values\"])\n",
    "n_hist_prices = 0\n",
    "\n",
    "# Define Agents\n",
    "quentin = library.agents.distAgentsWIP2.QRAgent(state_size, params[\"action_values\"], \"Quentin\",C=0, alternative_target = False,UCB=False,UCBc = 1,tree_horizon = 1,market_data_size=n_hist_prices)\n",
    "#brian = library.agents.distAgentsWIP2.C51Agent(state_size, params[\"action_values\"], \"Brian Appl 1hr md32\",C=150, alternative_target = True,UCB=False,UCBc = 0,tree_horizon = 4,market_data_size=n_hist_prices)\n",
    "tim = library.agents.baseAgents.TWAPAgent(3,\"TWAP_APPL\", len(params[\"action_values\"]))\n",
    "#print(brian.model.summary())\n",
    "agents = [\n",
    "    quentin\n",
    "]\n",
    "\n",
    "brian.learning_rate = 0.0001\n",
    "# NOTE: Cosine basis for Isabelle results in a lot of params...\n",
    "\n",
    "# Initialise Simulator\n",
    "# BS market\n",
    "'''\n",
    "simple_stock = bs_stock(1,0,0.0005) # No drift, 0.0005 vol\n",
    "simple_market = market(simple_stock,num_strats = len(agents))\n",
    "my_simulator = library.simulations.simulator(simple_market,agents,params,test_name = \"QR Testing\")\n",
    "'''\n",
    "\n",
    "# real stock testing\n",
    "# Retrieve data\n",
    "\n",
    "df1 = pd.read_csv(\"data/2020_05_04_SPX_yFinance\") # Load .csv\n",
    "df1 = df1[\"Adj Close.3\"][2:]\n",
    "df2 = pd.read_csv(\"data/2020_05_16_SPX_yFinance\") # Load .csv\n",
    "df2 = df2[\"Adj Close.3\"][2:]\n",
    "appl_data = pd.concat([df1,df2])\n",
    "print(\"Warning: dropping\",sum(pd.isnull(appl_data)), \"nan value(s)\")\n",
    "appl_data = appl_data.dropna()\n",
    "appl_data = appl_data.values # Extract APPL as np array\n",
    "appl_data = appl_data.astype(float) # convert any rouge strings to floats\n",
    "appl_stock = real_stock(appl_data,n_steps = params[\"terminal\"],recycle = True,n_train=10) # create stock - traded once per 6 minutes and recycled\n",
    "appl_market = market(appl_stock,num_strats = len(agents),n_hist_prices = n_hist_prices)\n",
    "#my_simulator = library.simulations.simulator(appl_market,agents,params,test_name = \"Apple Stock Testing\")\n",
    "\n",
    "simple_stock = bs_stock(1,0,0.0005) # No drift, 0.0005 vol\n",
    "simple_market = market(simple_stock,num_strats = len(agents))\n",
    "my_simulator = library.simulations.simulator(simple_market,agents,params,test_name = \"Simple Stock Testing\")\n",
    "\n",
    "my_simulator.train(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.075, 0.09, 0.1, 0.11, 0.15, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(my_simulator.possible_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_simulator.pretrain(n_iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9992502811797007\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9982515303571615\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9978772562140654\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9971291288547331\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.996630688910676\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9956345563710461\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9951368635264404\n",
      "2.5\n",
      "rate  2.5 price_adjust  0.9950124791926824\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9985011244377109\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9977525293526299\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9975031223974602\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9972537777862359\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.996506117860415\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9962570224691712\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9960079893439917\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9956345563710463\n",
      "12.5\n",
      "rate  12.5 price_adjust  0.9950124791926825\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.999750031247396\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9987507809245809\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9983763195976212\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9976278180810777\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9972537777862358\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.996257022469171\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9958834961263116\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9953856788429405\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9950124791926822\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9987507809245809\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9980019986673332\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.99775252935263\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9975031223974603\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9965061178604151\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9960079893439917\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9956345563710463\n",
      "12.5\n",
      "rate  12.5 price_adjust  0.9950124791926825\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9987507809245809\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9983763195976212\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9976278180810777\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.997378442299829\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9971291288547331\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9967552755332915\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9963815623805621\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9958834961263118\n",
      "17.5\n",
      "rate  17.5 price_adjust  0.9950124791926824\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9985011244377109\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9980019986673331\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9976278180810777\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9972537777862358\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9965061178604149\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9960079893439915\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9950124791926823\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.999000499833375\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9987507809245809\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.998501124437711\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9980019986673332\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.997253777786236\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9967552755332917\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9960079893439918\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9952612634092122\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9950124791926828\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9995001249791693\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9987507809245809\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9980019986673332\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9975031223974603\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9971291288547333\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9963815623805622\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9953856788429407\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9950124791926824\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9996250703037117\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9992502811797006\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9982515303571614\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9978772562140653\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.996879877730208\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9958834961263116\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9955101098295704\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9952612634092117\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9950124791926823\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.999750031247396\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9987507809245809\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9982515303571615\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9978772562140654\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9971291288547331\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.996630688910676\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9962570224691711\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9955101098295707\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9951368635264404\n",
      "2.5\n",
      "rate  2.5 price_adjust  0.9950124791926824\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.999000499833375\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9987507809245809\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9980019986673332\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9970044955033731\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.996630688910676\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9962570224691711\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.995261263409212\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9950124791926825\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9992502811797007\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.998875632575262\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9983763195976212\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9980019986673331\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9976278180810777\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9972537777862358\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.997004495503373\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9962570224691711\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.995261263409212\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9950124791926825\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.999000499833375\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9986259448793806\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9983763195976212\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9980019986673331\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9975031223974602\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9967552755332916\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9957590184693117\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.995261263409212\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9950124791926825\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9992502811797007\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9987507809245809\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9983763195976212\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9980019986673331\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9972537777862359\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9962570224691711\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9960079893439916\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9955101098295707\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9950124791926824\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.999000499833375\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9980019986673331\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9976278180810777\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.997378442299829\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.997004495503373\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.996506117860415\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9962570224691712\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9958834961263118\n",
      "10.0\n",
      "rate  10.0 price_adjust  0.9953856788429407\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9950124791926824\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9996250703037117\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9986259448793806\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9982515303571614\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9972537777862358\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.996879877730208\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9966306889106759\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.996381562380562\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9961324981242962\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9958834961263118\n",
      "17.5\n",
      "rate  17.5 price_adjust  0.9950124791926824\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.999000499833375\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9982515303571615\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9980019986673332\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.997253777786236\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9965061178604151\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9961324981242963\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9957590184693117\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9950124791926825\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.999750031247396\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.9993751952718163\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9991253827008708\n",
      "5.0\n",
      "rate  5.0 price_adjust  0.9988756325752621\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9981267567143821\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.99775252935263\n",
      "7.5\n",
      "rate  7.5 price_adjust  0.997378442299829\n",
      "20.0\n",
      "rate  20.0 price_adjust  0.9963815623805621\n",
      "15.0\n",
      "rate  15.0 price_adjust  0.9956345563710461\n",
      "12.5\n",
      "rate  12.5 price_adjust  0.9950124791926824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-66f76c34e8fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#epsilon_decays = [0.9992,0.999,1,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_decays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    204\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update target network if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/baseAgents.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmem_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                         \u001b[0;31m#print(\"replay state\",state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, state, action_index, reward, next_state, done, mem_index)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;31m#print(\"predictions\",self.predict(next_state,quantiles_selected = quantiles_selected))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0;31m#print(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    457\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                 \u001b[0mnext_state_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_state_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_action_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                                 \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_quantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_quantiles\u001b[0;34m(self, state_action, target)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;31m#state_action.shape = (1,len(state_action))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult_scaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3801\u001b[0;31m         expand_composites=True)\n\u001b[0m\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \"\"\"\n\u001b[0;32m--> 552\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    504\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     final_index, packed = _packed_nest_with_indices(structure, flat_sequence,\n\u001b[0;32m--> 506\u001b[0;31m                                                     0, is_seq, sequence_fn)\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_seq, sequence_fn)\u001b[0m\n\u001b[1;32m    465\u001b[0m   \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m       new_index, child = _packed_nest_with_indices(s, flat, index, is_seq,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_yield_value\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_sorted_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_yield_sorted_items\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#epsilon_decays = [0.9992,0.999,1,1]\n",
    "my_simulator.train(epsilon_decay = epsilon_decays, n_episodes = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6afb4e3434fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_decays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    201\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update target network if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/baseAgents.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmem_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                         \u001b[0;31m#print(\"replay state\",state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, state, action_index, reward, next_state, done, mem_index)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m#print(\"loss\", self.huber_loss_quantile(self.quantiles,1)(target_f,self.predict_quantiles(state,action_index,self.quantiles,target = False)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \"\"\"\n\u001b[1;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3497\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3405\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3550\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3551\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3552\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         \u001b[0mtranspose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'destination'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \"\"\"\n\u001b[1;32m   1600\u001b[0m     \u001b[0;31m# Optimization to speed-up the most common cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_simulator.train(epsilon_decay = epsilon_decays, n_episodes = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8124c1b50556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepsilons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#epsilon_decays = [0.999,0.999,1,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_decays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/simulations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_episodes, epsilon, epsilon_decay, show_details, evaluate)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                                                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update target network if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/baseAgents.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmem_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0;31m#print(\"replay state\",state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, state, action_index, reward, next_state, done, mem_index)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0;31m#print(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    428\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mnext_action_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                                         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhorizon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                                         \u001b[0mtree_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    428\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mnext_action_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                                         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhorizon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                                         \u001b[0mtree_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    428\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mnext_action_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                                         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhorizon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                                         \u001b[0mtree_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    428\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mnext_action_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                                         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhorizon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                                         \u001b[0mtree_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, reward, next_state, done, horizon, mem_index)\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                         \u001b[0mnext_action_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mhorizon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmem_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                                 \u001b[0mstate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state, target)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Imperial/Thesis/ThesisCode/library/agents/distAgentsWIP2.py\u001b[0m in \u001b[0;36mpredict_action\u001b[0;34m(self, state, action_index, target)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;31m#print(\"predict_action output\",self.model.predict([state_action,self.quantiles]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# This function needs to be rolled into predict_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epsilons = [0.2,0.2,0.22,0.22,1]\n",
    "#epsilon_decays = [0.999,0.999,1,1]\n",
    "my_simulator.train(epsilon = epsilons, epsilon_decay = epsilon_decays, n_episodes = 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add twap stat to final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14515c5c0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.ylim([9,10])\n",
    "twap_stat = 9.849\n",
    "plt.plot([0, 175], [twap_stat, twap_stat], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "state = [[0,0]]\n",
    "actions = [2,4]\n",
    "for action in actions:\n",
    "    quants = quentin.predict_quantiles(state,action)[0]\n",
    "    quants = quants[:len(quants)-1]\n",
    "    #print(quants)\n",
    "    plt.hist(quants,bins = 17,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2,3])\n",
    "np.add.reduce(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 20\n"
     ]
    }
   ],
   "source": [
    "res = (19,20)\n",
    "x,y,*z = res\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  AAPL\n",
      "1                   NaN\n",
      "2    288.79998779296875\n",
      "3     288.2250061035156\n",
      "4    288.07000732421875\n",
      "Name: Adj Close.3, dtype: object\n",
      "0                 AAPL\n",
      "1                  NaN\n",
      "2    312.8826904296875\n",
      "3    312.2799987792969\n",
      "4    311.7300109863281\n",
      "Name: Adj Close.3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"data/2020_05_04_SPX_yFinance\") # Load .csv\n",
    "df2 = pd.read_csv(\"data/2020_05_16_SPX_yFinance\") # Load .csv\n",
    "print(df1[\"Adj Close.3\"].head())\n",
    "print(df2[\"Adj Close.3\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tobyg/OptEx\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tobyg/OptEx/runs/2k7i5l4j\" target=\"_blank\">https://app.wandb.ai/tobyg/OptEx/runs/2k7i5l4j</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.0 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "my_simulator_eval = library.simulations.simulator(appl_market,agents,params,test_name = \"Apple Stock Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a sample episode post training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Agent 0 predict [[0.99768007 0.9976507  0.9976271  0.99762124 0.9976153  0.99759173\n",
      "  0.9975623 ]]\n",
      "State[0]:  [array([[ 1., -1.]]), array([[[-2.61278523e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00]]])] Actions[0]:  0 Rewards[0]:  [0.02449369] Next_states[0]:  [array([[ 0.951, -0.95 ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.97324276 0.9732134  0.97318983 0.9731839  0.973178   0.97315437\n",
      "  0.97312504]]\n",
      "Agent 0 predict [[0.97324276 0.9732134  0.97318983 0.9731839  0.973178   0.97315437\n",
      "  0.97312504]]\n",
      "State[0]:  [array([[ 0.951, -0.95 ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05]]])] Actions[0]:  0 Rewards[0]:  [0.02449069] Next_states[0]:  [array([[ 0.902, -0.9  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.9487666  0.94876504 0.94875246 0.9487466  0.9487408  0.9487171\n",
      "  0.9486878 ]]\n",
      "Agent 0 predict [[0.9487666  0.94876504 0.94875246 0.9487466  0.9487408  0.9487171\n",
      "  0.9486878 ]]\n",
      "State[0]:  [array([[ 0.902, -0.9  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02448897] Next_states[0]:  [array([[ 0.853, -0.85 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.9242104  0.92420554 0.9242042  0.9242038  0.9242037  0.92420226\n",
      "  0.9241957 ]]\n",
      "Agent 0 predict [[0.9242104  0.92420554 0.9242042  0.9242038  0.9242037  0.92420226\n",
      "  0.9241957 ]]\n",
      "State[0]:  [array([[ 0.853, -0.85 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02448597] Next_states[0]:  [array([[ 0.804, -0.8  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.8996588  0.89965034 0.8996596  0.8996619  0.89966327 0.89966893\n",
      "  0.899676  ]]\n",
      "Agent 0 predict [[0.8996588  0.89965034 0.8996596  0.8996619  0.89966327 0.89966893\n",
      "  0.899676  ]]\n",
      "State[0]:  [array([[ 0.804, -0.8  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02448276] Next_states[0]:  [array([[ 0.755, -0.75 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.87518406 0.8751983  0.8752077  0.87520957 0.875211   0.8752166\n",
      "  0.87522364]]\n",
      "Agent 0 predict [[0.87518406 0.8751983  0.8752077  0.87520957 0.875211   0.8752166\n",
      "  0.87522364]]\n",
      "State[0]:  [array([[ 0.755, -0.75 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02448061] Next_states[0]:  [array([[ 0.706, -0.7  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.85073036 0.8507421  0.85075164 0.850754   0.85075647 0.8507642\n",
      "  0.8507713 ]]\n",
      "Agent 0 predict [[0.85073036 0.8507421  0.85075164 0.850754   0.85075647 0.8507642\n",
      "  0.8507713 ]]\n",
      "State[0]:  [array([[ 0.706, -0.7  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02447761] Next_states[0]:  [array([[ 0.657, -0.65 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.82627356 0.8262856  0.82629514 0.8262974  0.82629997 0.82630944\n",
      "  0.82631874]]\n",
      "Agent 0 predict [[0.82627356 0.8262856  0.82629514 0.8262974  0.82629997 0.82630944\n",
      "  0.82631874]]\n",
      "State[0]:  [array([[ 0.657, -0.65 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02447461] Next_states[0]:  [array([[ 0.608, -0.6  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.8018161  0.8018281  0.8018376  0.80184    0.80184233 0.80185205\n",
      "  0.8018639 ]]\n",
      "Agent 0 predict [[0.8018161  0.8018281  0.8018376  0.80184    0.80184233 0.80185205\n",
      "  0.8018639 ]]\n",
      "State[0]:  [array([[ 0.608, -0.6  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02447161] Next_states[0]:  [array([[ 0.559, -0.55 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.77735865 0.77737063 0.77738017 0.77738255 0.7773849  0.77739453\n",
      "  0.77740633]]\n",
      "Agent 0 predict [[0.77735865 0.77737063 0.77738017 0.77738255 0.7773849  0.77739453\n",
      "  0.77740633]]\n",
      "State[0]:  [array([[ 0.559, -0.55 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04]]])] Actions[0]:  0 Rewards[0]:  [0.02446798] Next_states[0]:  [array([[ 0.51, -0.5 ]]), array([[[ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.7529012  0.7529131  0.75292265 0.7529251  0.7529275  0.7529369\n",
      "  0.752949  ]]\n",
      "Agent 0 predict [[0.7529012  0.7529131  0.75292265 0.7529251  0.7529275  0.7529369\n",
      "  0.752949  ]]\n",
      "State[0]:  [array([[ 0.51, -0.5 ]]), array([[[ 2.61278523e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02446541] Next_states[0]:  [array([[ 0.461, -0.45 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.7284437  0.7284556  0.7284652  0.7284676  0.72847    0.7284794\n",
      "  0.72849154]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 predict [[0.7284437  0.7284556  0.7284652  0.7284676  0.72847    0.7284794\n",
      "  0.72849154]]\n",
      "State[0]:  [array([[ 0.461, -0.45 ]]), array([[[ 5.22557046e-05],\n",
      "        [ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02446198] Next_states[0]:  [array([[ 0.412, -0.4  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.7039863 0.7039982 0.7040076 0.7040101 0.7040126 0.7040221 0.7040341]]\n",
      "Agent 0 predict [[0.7039863 0.7039982 0.7040076 0.7040101 0.7040126 0.7040221 0.7040341]]\n",
      "State[0]:  [array([[ 0.412, -0.4  ]]), array([[[ 5.22557046e-05],\n",
      "        [ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03]]])] Actions[0]:  0 Rewards[0]:  [0.0244592] Next_states[0]:  [array([[ 0.363, -0.35 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.6795289  0.67954075 0.6795503  0.6795527  0.6795551  0.67956465\n",
      "  0.6795766 ]]\n",
      "Agent 0 predict [[0.6795289  0.67954075 0.6795503  0.6795527  0.6795551  0.67956465\n",
      "  0.6795766 ]]\n",
      "State[0]:  [array([[ 0.363, -0.35 ]]), array([[[ 4.35464205e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03]]])] Actions[0]:  0 Rewards[0]:  [0.0244562] Next_states[0]:  [array([[ 0.314, -0.3  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.6550713  0.6550833  0.65509284 0.6550953  0.65509766 0.65510714\n",
      "  0.6551192 ]]\n",
      "Agent 0 predict [[0.6550713  0.6550833  0.65509284 0.6550953  0.65509766 0.65510714\n",
      "  0.6551192 ]]\n",
      "State[0]:  [array([[ 0.314, -0.3  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02445321] Next_states[0]:  [array([[ 0.265, -0.25 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.6306139  0.6306258  0.6306354  0.63063776 0.6306402  0.6306497\n",
      "  0.6306616 ]]\n",
      "Agent 0 predict [[0.6306139  0.6306258  0.6306354  0.63063776 0.6306402  0.6306497\n",
      "  0.6306616 ]]\n",
      "State[0]:  [array([[ 0.265, -0.25 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02445021] Next_states[0]:  [array([[ 0.216, -0.2  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.6061564  0.6061682  0.6061779  0.60618025 0.60618263 0.60619223\n",
      "  0.60620415]]\n",
      "Agent 0 predict [[0.6061564  0.6061682  0.6061779  0.60618025 0.60618263 0.60619223\n",
      "  0.60620415]]\n",
      "State[0]:  [array([[ 0.216, -0.2  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02444679] Next_states[0]:  [array([[ 0.167, -0.15 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.58169895 0.5817108  0.58172053 0.58172286 0.58172673 0.5817427\n",
      "  0.58176255]]\n",
      "Agent 0 predict [[0.58169895 0.5817108  0.58172053 0.58172286 0.58172673 0.5817427\n",
      "  0.58176255]]\n",
      "State[0]:  [array([[ 0.167, -0.15 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02444443] Next_states[0]:  [array([[ 0.118, -0.1  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.55724955 0.55727375 0.55728966 0.5572937  0.5572977  0.5573136\n",
      "  0.5573336 ]]\n",
      "Agent 0 predict [[0.55724955 0.55727375 0.55728966 0.5572937  0.5572977  0.5573136\n",
      "  0.5573336 ]]\n",
      "State[0]:  [array([[ 0.118, -0.1  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02444144] Next_states[0]:  [array([[ 0.069, -0.05 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.53279436 0.5328304  0.53285927 0.5328647  0.5328686  0.5328846\n",
      "  0.5329045 ]]\n",
      "Agent 0 predict [[0.53279436 0.5328304  0.53285927 0.5328647  0.5328686  0.5328846\n",
      "  0.5329045 ]]\n",
      "State[0]:  [array([[ 0.069, -0.05 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02443866] Next_states[0]:  [array([[2.0000000e-02, 3.1918912e-16]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.5083392  0.5083753  0.50840414 0.5084113  0.5084185  0.50844735\n",
      "  0.50847554]]\n",
      "Agent 0 predict [[0.5083392  0.5083753  0.50840414 0.5084113  0.5084185  0.50844735\n",
      "  0.50847554]]\n",
      "State[0]:  [array([[2.0000000e-02, 3.1918912e-16]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02443566] Next_states[0]:  [array([[-0.029,  0.05 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03]]])] Done[0]:  False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 next predict [[0.48388416 0.48392022 0.48394898 0.4839562  0.4839634  0.48399222\n",
      "  0.48402822]]\n",
      "Agent 0 predict [[0.48388416 0.48392022 0.48394898 0.4839562  0.4839634  0.48399222\n",
      "  0.48402822]]\n",
      "State[0]:  [array([[-0.029,  0.05 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02443267] Next_states[0]:  [array([[-0.078,  0.1  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.45942897 0.45946503 0.4594938  0.459501   0.4595082  0.45953706\n",
      "  0.45957315]]\n",
      "Agent 0 predict [[0.45942897 0.45946503 0.4594938  0.459501   0.4595082  0.45953706\n",
      "  0.45957315]]\n",
      "State[0]:  [array([[-0.078,  0.1  ]]), array([[[ 6.09649887e-05],\n",
      "        [ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02442946] Next_states[0]:  [array([[-0.127,  0.15 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.4349738  0.4350099  0.4350387  0.4350459  0.43505317 0.43508193\n",
      "  0.43511802]]\n",
      "Agent 0 predict [[0.4349738  0.4350099  0.4350387  0.4350459  0.43505317 0.43508193\n",
      "  0.43511802]]\n",
      "State[0]:  [array([[-0.127,  0.15 ]]), array([[[ 6.09649887e-05],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02442668] Next_states[0]:  [array([[-0.176,  0.2  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.41051868 0.4105547  0.4105835  0.41059074 0.41059798 0.41062674\n",
      "  0.41066283]]\n",
      "Agent 0 predict [[0.41051868 0.4105547  0.4105835  0.41059074 0.41059798 0.41062674\n",
      "  0.41066283]]\n",
      "State[0]:  [array([[-0.176,  0.2  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02442199] Next_states[0]:  [array([[-0.225,  0.25 ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.3860635  0.38609955 0.38612834 0.38613555 0.3861428  0.38617158\n",
      "  0.3862077 ]]\n",
      "Agent 0 predict [[0.3860635  0.38609955 0.38612834 0.38613555 0.3861428  0.38617158\n",
      "  0.3862077 ]]\n",
      "State[0]:  [array([[-0.225,  0.25 ]]), array([[[ 8.70928410e-06],\n",
      "        [ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03]]])] Actions[0]:  0 Rewards[0]:  [0.024419] Next_states[0]:  [array([[-0.274,  0.3  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.36160836 0.3616444  0.36167324 0.36168045 0.36168766 0.36171645\n",
      "  0.36175254]]\n",
      "Agent 0 predict [[0.36160836 0.3616444  0.36167324 0.36168045 0.36168766 0.36171645\n",
      "  0.36175254]]\n",
      "State[0]:  [array([[-0.274,  0.3  ]]), array([[[ 8.70928410e-06],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02441643] Next_states[0]:  [array([[-0.323,  0.35 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.33715323 0.33718926 0.33721805 0.3372253  0.33723253 0.33726126\n",
      "  0.33729738]]\n",
      "Agent 0 predict [[0.33715323 0.33718926 0.33721805 0.3372253  0.33723253 0.33726126\n",
      "  0.33729738]]\n",
      "State[0]:  [array([[-0.323,  0.35 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02441387] Next_states[0]:  [array([[-0.372,  0.4  ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.31269807 0.31273407 0.31276292 0.3127701  0.31277734 0.31280616\n",
      "  0.31284222]]\n",
      "Agent 0 predict [[0.31269807 0.31273407 0.31276292 0.3127701  0.31277734 0.31280616\n",
      "  0.31284222]]\n",
      "State[0]:  [array([[-0.372,  0.4  ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02441088] Next_states[0]:  [array([[-0.421,  0.45 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.2882429  0.28827894 0.2883078  0.28831494 0.28832218 0.28835103\n",
      "  0.2883871 ]]\n",
      "Agent 0 predict [[0.2882429  0.28827894 0.2883078  0.28831494 0.28832218 0.28835103\n",
      "  0.2883871 ]]\n",
      "State[0]:  [array([[-0.421,  0.45 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02440767] Next_states[0]:  [array([[-0.47,  0.5 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.26378772 0.2638238  0.2638526  0.2638598  0.26386705 0.26389587\n",
      "  0.2639319 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 predict [[0.26378772 0.2638238  0.2638526  0.2638598  0.26386705 0.26389587\n",
      "  0.2639319 ]]\n",
      "State[0]:  [array([[-0.47,  0.5 ]]), array([[[ 1.74185682e-05],\n",
      "        [ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02440468] Next_states[0]:  [array([[-0.519,  0.55 ]]), array([[[ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03],\n",
      "        [-3.65957812e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.2393326  0.23936866 0.23939747 0.23940468 0.2394119  0.23944074\n",
      "  0.23947677]]\n",
      "Agent 0 predict [[0.2393326  0.23936866 0.23939747 0.23940468 0.2394119  0.23944074\n",
      "  0.23947677]]\n",
      "State[0]:  [array([[-0.519,  0.55 ]]), array([[[ 0.00000000e+00],\n",
      "        [-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03],\n",
      "        [-3.65957812e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02440169] Next_states[0]:  [array([[-0.568,  0.6  ]]), array([[[-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03],\n",
      "        [-3.65957812e-03],\n",
      "        [-3.78162234e-03]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.21487746 0.21491347 0.21494232 0.21494953 0.21495675 0.21498561\n",
      "  0.21502163]]\n",
      "Agent 0 predict [[0.21487746 0.21491347 0.21494232 0.21494953 0.21495675 0.21498561\n",
      "  0.21502163]]\n",
      "State[0]:  [array([[-0.568,  0.6  ]]), array([[[-2.61278523e-05],\n",
      "        [-1.48617149e-04],\n",
      "        [-2.18848538e-04],\n",
      "        [-3.41314228e-04],\n",
      "        [-4.72469934e-04],\n",
      "        [-5.60088752e-04],\n",
      "        [-6.82512643e-04],\n",
      "        [-8.04921537e-04],\n",
      "        [-9.27315438e-04],\n",
      "        [-1.07579341e-03],\n",
      "        [-1.18075689e-03],\n",
      "        [-1.32049986e-03],\n",
      "        [-1.43413412e-03],\n",
      "        [-1.55645094e-03],\n",
      "        [-1.67875279e-03],\n",
      "        [-1.80103965e-03],\n",
      "        [-1.94069599e-03],\n",
      "        [-2.03687727e-03],\n",
      "        [-2.15912027e-03],\n",
      "        [-2.27265925e-03],\n",
      "        [-2.39487336e-03],\n",
      "        [-2.51707251e-03],\n",
      "        [-2.64794253e-03],\n",
      "        [-2.76142589e-03],\n",
      "        [-2.95304987e-03],\n",
      "        [-3.07518064e-03],\n",
      "        [-3.17993327e-03],\n",
      "        [-3.28467520e-03],\n",
      "        [-3.40676534e-03],\n",
      "        [-3.53751894e-03],\n",
      "        [-3.65957812e-03],\n",
      "        [-3.78162234e-03]]])] Actions[0]:  0 Rewards[0]:  [0.02439807] Next_states[0]:  [array([[-0.617,  0.65 ]]), array([[[-0.00014862],\n",
      "        [-0.00021885],\n",
      "        [-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.19042228 0.19045831 0.19048715 0.19049439 0.19050162 0.19053042\n",
      "  0.19056647]]\n",
      "Agent 0 predict [[0.19042228 0.19045831 0.19048715 0.19049439 0.19050162 0.19053042\n",
      "  0.19056647]]\n",
      "State[0]:  [array([[-0.617,  0.65 ]]), array([[[-0.00014862],\n",
      "        [-0.00021885],\n",
      "        [-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968]]])] Actions[0]:  0 Rewards[0]:  [0.02439614] Next_states[0]:  [array([[-0.666,  0.7  ]]), array([[[-0.00021885],\n",
      "        [-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.16596714 0.16600317 0.16603203 0.16603923 0.16604646 0.16607526\n",
      "  0.16611132]]\n",
      "Agent 0 predict [[0.16596714 0.16600317 0.16603203 0.16603923 0.16604646 0.16607526\n",
      "  0.16611132]]\n",
      "State[0]:  [array([[-0.666,  0.7  ]]), array([[[-0.00021885],\n",
      "        [-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832]]])] Actions[0]:  0 Rewards[0]:  [0.02439315] Next_states[0]:  [array([[-0.715,  0.75 ]]), array([[[-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.141512   0.14154804 0.14157687 0.14158408 0.1415913  0.14162011\n",
      "  0.14165618]]\n",
      "Agent 0 predict [[0.141512   0.14154804 0.14157687 0.14158408 0.1415913  0.14162011\n",
      "  0.14165618]]\n",
      "State[0]:  [array([[-0.715,  0.75 ]]), array([[[-0.00034131],\n",
      "        [-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032]]])] Actions[0]:  0 Rewards[0]:  [0.02439016] Next_states[0]:  [array([[-0.764,  0.8  ]]), array([[[-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.11705685 0.11709289 0.11712173 0.11712894 0.11713615 0.11716498\n",
      "  0.11720103]]\n",
      "Agent 0 predict [[0.11705685 0.11709289 0.11712173 0.11712894 0.11713615 0.11716498\n",
      "  0.11720103]]\n",
      "State[0]:  [array([[-0.764,  0.8  ]]), array([[[-0.00047247],\n",
      "        [-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231]]])] Actions[0]:  0 Rewards[0]:  [0.0243876] Next_states[0]:  [array([[-0.813,  0.85 ]]), array([[[-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.09260169 0.09263774 0.09266658 0.09267379 0.09268098 0.09270985\n",
      "  0.09274588]]\n",
      "Agent 0 predict [[0.09260169 0.09263774 0.09266658 0.09267379 0.09268098 0.09270985\n",
      "  0.09274588]]\n",
      "State[0]:  [array([[-0.813,  0.85 ]]), array([[[-0.00056009],\n",
      "        [-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694]]])] Actions[0]:  0 Rewards[0]:  [0.02438504] Next_states[0]:  [array([[-0.862,  0.9  ]]), array([[[-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694],\n",
      "        [-0.00446155]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.06814654 0.06818259 0.06821141 0.06821864 0.06822585 0.06825468\n",
      "  0.06829073]]\n",
      "Agent 0 predict [[0.06814654 0.06818259 0.06821141 0.06821864 0.06822585 0.06825468\n",
      "  0.06829073]]\n",
      "State[0]:  [array([[-0.862,  0.9  ]]), array([[[-0.00068251],\n",
      "        [-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694],\n",
      "        [-0.00446155]]])] Actions[0]:  0 Rewards[0]:  [0.02438184] Next_states[0]:  [array([[-0.911,  0.95 ]]), array([[[-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694],\n",
      "        [-0.00446155],\n",
      "        [-0.00459217]]])] Done[0]:  False\n",
      "Agent 0 next predict [[0.04369139 0.04372744 0.04375628 0.04376349 0.0437707  0.04379954\n",
      "  0.04383558]]\n",
      "Agent 0 predict [[0.04369139 0.04372744 0.04375628 0.04376349 0.0437707  0.04379954\n",
      "  0.04383558]]\n",
      "State[0]:  [array([[-0.911,  0.95 ]]), array([[[-0.00080492],\n",
      "        [-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694],\n",
      "        [-0.00446155],\n",
      "        [-0.00459217]]])] Actions[0]:  0 Rewards[0]:  [0.04427157] Next_states[0]:  [array([[-1.,  1.]]), array([[[-0.00092732],\n",
      "        [-0.00107579],\n",
      "        [-0.00118076],\n",
      "        [-0.0013205 ],\n",
      "        [-0.00143413],\n",
      "        [-0.00155645],\n",
      "        [-0.00167875],\n",
      "        [-0.00180104],\n",
      "        [-0.0019407 ],\n",
      "        [-0.00203688],\n",
      "        [-0.00215912],\n",
      "        [-0.00227266],\n",
      "        [-0.00239487],\n",
      "        [-0.00251707],\n",
      "        [-0.00264794],\n",
      "        [-0.00276143],\n",
      "        [-0.00295305],\n",
      "        [-0.00307518],\n",
      "        [-0.00317993],\n",
      "        [-0.00328468],\n",
      "        [-0.00340677],\n",
      "        [-0.00353752],\n",
      "        [-0.00365958],\n",
      "        [-0.00378162],\n",
      "        [-0.00392968],\n",
      "        [-0.00400832],\n",
      "        [-0.00413032],\n",
      "        [-0.00425231],\n",
      "        [-0.00435694],\n",
      "        [-0.00446155],\n",
      "        [-0.00459217],\n",
      "        [-0.0047141 ]]])] Done[0]:  True\n",
      "Agent 0 next predict [[-0.00074168 -0.00070563 -0.00067679 -0.00066958 -0.00066238 -0.00063354\n",
      "  -0.00059749]]\n"
     ]
    }
   ],
   "source": [
    "print(quentin.epsilon)\n",
    "actions = np.array([0])\n",
    "my_simulator.episode(evaluate = 1,verbose = 1)\n",
    "#david.predict[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Action value distributions for Distributional Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(state,bar_agent.predict(state))\\nprint(state1,bar_agent.predict(state1))\\n#state = np.reshape(np.append(state,1), [1, 3])\\n#print(state)\\n#print(daisy.model.get_weights())\\n#print(\"state probs\", daisy.probs(state))\\n#print(\"pred probs\", bar_agent.model.predict(state1)[0])#-bar_agent.model.predict(state)[0])\\nplt.legend()\\nprint(bar_agent.probs(state,bar_act)[0])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "bar_agent = brian #daisy15N11   daisy100N51\n",
    "#plt.plot(my_simulator.eval_rewards_mean[:,1],label = \"act \" + str(1))\n",
    "#print(my_simulator.eval_rewards_mean)\n",
    "#print(my_simulator.env.reset())\n",
    "#episode_actions = np.zeros((7,3))\n",
    "#print(my_simulator.env.step([1,5,6,6]))\n",
    "#state = my_simulator.env.reset()[0]\n",
    "#print(my_simulator.env.cash)\n",
    "loc = [1,-1]\n",
    "md = np.ones(32)\n",
    "loc = np.reshape(loc, [1, 2])\n",
    "#md = np.reshape(md, [1, 32])\n",
    "state = loc\n",
    "\n",
    "bar_act = 3\n",
    "#plt.bar(bar_agent.z,bar_agent.probs(state,bar_act)[0],alpha = 0.4,width = 0.002,label = f\"state {state}, act {bar_act}\")\n",
    "bar_act = 4\n",
    "plt.bar(bar_agent.z,bar_agent.probs(state,bar_act)[0],alpha = 0.4,width = 0.002,label = f\"state {state}, act {bar_act}\")\n",
    "\n",
    "\n",
    "#plt.bar(bar_agent.z,bar_agent.probs(state1,bar_act)[0],alpha = 0.4,width = 0.004,label = f\"state {state1}, act {bar_act}\")\n",
    "#plt.bar(bar_agent.z,bar_agent.probs(state2,bar_act)[0],alpha = 0.4,width = 0.004,label = f\"state {state2}, act {bar_act}\")\n",
    "#print(bar_agent.probs(state))\n",
    "#print(david30.predict(state))\n",
    "'''\n",
    "print(state,bar_agent.predict(state))\n",
    "print(state1,bar_agent.predict(state1))\n",
    "#state = np.reshape(np.append(state,1), [1, 3])\n",
    "#print(state)\n",
    "#print(daisy.model.get_weights())\n",
    "#print(\"state probs\", daisy.probs(state))\n",
    "#print(\"pred probs\", bar_agent.model.predict(state1)[0])#-bar_agent.model.predict(state)[0])\n",
    "plt.legend()\n",
    "print(bar_agent.probs(state,bar_act)[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 41 artists>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline  \n",
    "plt.bar(bar_agent.z,bar_agent.probs(state,bar_act)[0],alpha = 0.4,width = 0.05,label = f\"act {bar_act}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.35744632e-05 5.86628584e-06 2.58160457e-06 5.99464104e-07\n",
      "  4.74560938e-03]]\n",
      "5.994723341004875e-07\n",
      "[[5.5182400e-06 4.3750665e-09 7.5223115e-06 3.8480178e-07 4.1647644e-07\n",
      "  3.4923675e-09 2.4237238e-06 1.4744355e-09 3.1187987e-08 1.6907694e-11\n",
      "  5.8795553e-08 1.1792116e-06 5.0734457e-08 2.7221098e-10 4.8862375e-08\n",
      "  2.0434729e-06 2.8074530e-06 3.4797912e-07 1.7652665e-10 1.5957380e-06\n",
      "  9.9997032e-01 2.7648263e-12 3.7239647e-09 6.4975785e-09 1.3954185e-10\n",
      "  3.4414436e-06 6.0194715e-14 1.8028203e-08 6.9937067e-10 3.7105539e-07\n",
      "  6.1954063e-14 4.7340407e-09 8.1869040e-08 5.0627906e-09 1.4544144e-09\n",
      "  1.3242059e-06 3.8975507e-08 3.0195644e-12 1.6127088e-12 4.0010316e-14\n",
      "  1.1356373e-08]]\n",
      "[[-7.82182970e-05 -3.30417275e-05 -1.41244373e-05 -2.86881338e-06\n",
      "  -1.31347548e-02]]\n"
     ]
    }
   ],
   "source": [
    "state = [-1,0] \n",
    "state = np.reshape(state, [1, 2])\n",
    "print(brian.variance(state))\n",
    "print(brian.var_act(state,3))\n",
    "print(brian.probs(state,3,target = False))\n",
    "print(brian.predict(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Action value estimates for the first action over time\n",
    "If using a TWAP agent then add the average to denote the optimal action value for action 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd6911d3f89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_rewards_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtwap_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_rewards_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_simulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtwap_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwap_stat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(my_simulator.eval_rewards_mean.shape)\n",
    "twap_stat = np.mean(my_simulator.eval_rewards_mean[:,0])\n",
    "plt.plot([0, len(my_simulator.train_actions[:,0])], [twap_stat, twap_stat], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13ac8c048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAag0lEQVR4nO3de3hV1b3u8e+Pi8QUSiFAqwY3UUFFmiAGG7BlU9FN4MilgAr7qI2niNXjbjkVtnjB7e2xtVr1wTseeFIUCwgnQG2oVTFejqIJCmyRW1R2WaCHAIIiIrff+SOTdCVZWVngymXNvJ/nycOcY4w115gDeJnMNdcY5u6IiEjqa9XUHRARkeRQoIuIhIQCXUQkJBToIiIhoUAXEQmJNk31xl26dPEePXo01duLiKSklStX7nD3rrHqmizQe/ToQVlZWVO9vYhISjKz/6qrTrdcRERCQoEuIhISCnQRkZBQoIuIhIQCXUQkJOoNdDObbWbbzeyDOurNzGaYWbmZrTGzfsnvpoiI1CeRK/RCID9O/TCgZ/AzCXji23dLRESOVb3Pobv762bWI06TUcAcr5yHd4WZfc/MTnL3T5PUx1oGDx5cq+yyyy7j+uuvZ9++fQwfPrxWfUFBAQUFBezYsYNx48bVqr/uuuu4/PLL2bJlC1deeWWt+htvvJERI0awYcMGrr322lr1t912GxdddBGrVq1i8uTJtervvfdeBg4cyFtvvcUtt9xSq/7hhx+mb9++vPzyy9xzzz216p966inOPPNM/vznP/OHP/yhVv0zzzxD9+7dmT9/Pk88Ufvf1IULF9KlSxcKCwspLCysVV9cXEx6ejqPP/44CxYsqFVfUlICwAMPPMALL7xQre7EE09k2bJlANx999288sor1eozMjJYtGgRADfffDNvv/12tfrMzEyeffZZACZPnsyqVauq1ffq1YuZM2cCMGnSJDZu3Fitvm/fvjz88MMAXHHFFUQikWr1AwYM4Le//S0AY8eOZefOndXqhwwZwvTp0wEYNmwYX3/9dbX6Sy65hClTpgD6s6c/e8n5s3f0nJItGffQTwG2RO1HgrJazGySmZWZWVlFRUUS3lpERI6yRBa4CK7QX3D3PjHq/gL81t3fDPZfAf7d3VfGO2Zubq7rm6IiIsfGzFa6e26sumRcoUeA7lH7mcC2JBxXRESOQTICfSlwVfC0Sx6wpyHvn4uISGz1fihqZn8CBgNdzCwC/AfQFsDdnwSKgeFAObAPuLqhOisiInVL5CmXCfXUO/A/k9YjERE5LvqmqIhISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhkVCgm1m+mW0ws3Izmxaj/lQze9XM3jezNWY2PPldFRGReOoNdDNrDTwGDAN6AxPMrHeNZrcBC9z9XGA88HiyOyoiIvElcoV+PlDu7h+7+wFgHjCqRhsHvhtsdwS2Ja+LIiKSiEQC/RRgS9R+JCiLdgdwhZlFgGLg32IdyMwmmVmZmZVVVFQcR3dFRKQuiQS6xSjzGvsTgEJ3zwSGA8+YWa1ju/tMd89199yuXbsee29FRKROiQR6BOgetZ9J7VsqvwAWALj720Aa0CUZHRQRkcQkEuilQE8zyzKzE6j80HNpjTZ/B4YAmNnZVAa67qmIiDSiegPd3Q8BNwAvAuuofJplrZndZWYjg2Y3AteY2WrgT0CBu9e8LSMiIg2oTSKN3L2Yyg87o8tuj9r+ELgguV0TEZFjoW+KioiEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCT2HLiLhcfDgQSKRCPv372/qrkgcaWlpZGZm0rZt24Rfo0AXaWEikQgdOnSgR48emMWae0+amruzc+dOIpEIWVlZCb9Ot1xEWpj9+/eTkZGhMG/GzIyMjIxj/l+UAl2kBVKYN3/H83ukQBeRRheJRBg1ahQ9e/bk9NNP59e//jUHDhyI+5rdu3fz+OP/WN1y27ZtjBs3Lin9ueOOO3jggQeqlZWUlDBgwIBqZYcOHeL73/8+n3766TEdq7Eo0EWkUbk7Y8aMYfTo0WzatImNGzeyd+9ebr311rivqxnoJ598MgsXLmywfg4aNIhIJMLmzZuryl5++WX69OnDSSed1GDv+20o0EWkUS1fvpy0tDSuvvpqAFq3bs1DDz3E7Nmz2bdvH4WFhYwaNYr8/HzOPPNM7rzzTgCmTZvGRx99RN++fZk6dSqbN2+mT58+ABQWFjJ69GhGjBhBVlYWjz76KA8++CDnnnsueXl57Nq1C4Cnn36a/v37k5OTw9ixY9m3b1+d/WzVqhWXXnop8+fPryqbN28eEyZMSPhYgwcPpqysDIAdO3bQo0cPAA4fPszUqVPp378/2dnZPPXUU99yVIM+J+UoIpKyBg8eXOvn6JXwvn37YtYXFhYClSFVs64+a9eu5bzzzqtW9t3vfpdTTz2V8vJyAN59913mzp3LqlWreP755ykrK+N3v/sdp59+OqtWreL++++vddwPPviA5557jnfffZdbb72V9PR03n//fQYMGMCcOXMAGDNmDKWlpaxevZqzzz6bWbNmxe3rhAkTmDdvHgDffPMNxcXFjB079riOFW3WrFl07NiR0tJSSktLefrpp/nkk08Sfn1d9NiiiDQqd4/5gV90+cUXX0xGRgZQGZxvvvkmo0ePjnvcn/70p3To0IEOHTrQsWNHRowYAcAPf/hD1qxZA1SG/m233cbu3bvZu3cvQ4cOjXvM/v37s3fvXjZs2MC6devIy8ujU6dOx3WsaH/7299Ys2ZN1S2jPXv2sGnTpmN6RDEWBbpIC1dSUlJnXXp6etz6Ll26xK2P5ZxzzmHRokXVyr744gu2bNnC6aefzsqVK2sFfiJPfLRr165qu1WrVlX7rVq14tChQwAUFBSwePFicnJyKCwsTKjv48ePZ968eaxbt67qdkuix2rTpg1HjhwBqPYIorvzyCOPHNM/AonQLRcRaVRDhgxh3759VbdBDh8+zI033khBQQHp6ekAvPTSS+zatYuvv/6axYsXc8EFF9ChQwe+/PLLb/XeX375JSeddBIHDx5k7ty5Cb1mwoQJPPvssyxfvpyRI0dWlSdyrB49erBy5UqAah/gDh06lCeeeIKDBw8CsHHjRr766qvjPa0qCnQRaVRmRlFREc8//zw9e/akV69epKWlce+991a1+fGPf8yVV15J3759GTt2LLm5uWRkZHDBBRfQp08fpk6delzvfffdd/OjH/2Iiy++mLPOOiuh1/Tu3Zv09HQuvPBCvvOd7xzTsaZMmcITTzzBwIED2bFjR1X5xIkT6d27N/369aNPnz5ce+21Vf+L+DasqdZyzs3N9aOf/opI41m3bh1nn312U3ejToWFhZSVlfHoo482dVeaXKzfKzNb6e65sdrrCl1EJCT0oaiINCsFBQUUFBQ0dTdSkq7QRURCQoEuIhISCnQRkZBQoIuIhIQCXUSatZKSEt56662Yde7Or371K8444wyys7N57733Grl3zYsCXUSatXiBvmzZMjZt2sSmTZuYOXMm1113XSP3rnlRoItIoxs9ejTnnXce55xzDjNnzqwq/+tf/0q/fv3IyclhyJAhbN68mSeffJKHHnqIvn378sYbb1Q7zpIlS7jqqqswM/Ly8ti9e3fcxSfCTs+hi7Rgd/55LR9u+yKpx+x98nf5jxHnxG0ze/ZsOnfuzNdff03//v0ZO3YsR44c4ZprruH1118nKyuLXbt20blzZ375y1/Svn17pkyZUus4W7dupXv37lX7mZmZbN26tdkuQNHQErpCN7N8M9tgZuVmNq2ONpeZ2YdmttbMnktuN0UkTGbMmEFOTg55eXls2bKFTZs2sWLFCgYNGlQ1hWznzp3rPU6sqUta8nqp9V6hm1lr4DHgYiAClJrZUnf/MKpNT+Bm4AJ3/9zMujVUh0Ukeeq7km4IJSUlvPzyy7z99tukp6czePBg9u/fX+c86fFkZmayZcuWqv1IJMLJJ5+c7C6njESu0M8Hyt39Y3c/AMwDRtVocw3wmLt/DuDu25PbTREJiz179tCpUyfS09NZv349K1asAGDAgAG89tprVSv3HF02Lt60uSNHjmTOnDm4OytWrKBjx44t9nYLJBbopwBbovYjQVm0XkAvM/u/ZrbCzPJjHcjMJplZmZmVVVRUHF+PRSSl5efnc+jQIbKzs5k+fTp5eXkAdO3alZkzZzJmzBhycnK4/PLLARgxYgRFRUUxPxQdPnw4p512GmeccQbXXHNNtUWkW6J6p881s0uBoe4+Mdi/Ejjf3f8tqs0LwEHgMiATeAPo4+676zqups8VaRrNffpc+YeGmD43AnSP2s8EtsVos8TdD7r7J8AGoGfCvRYRkW8tkUAvBXqaWZaZnQCMB5bWaLMY+CmAmXWh8hbMx8nsqIiIxFdvoLv7IeAG4EVgHbDA3dea2V1mdnSBvReBnWb2IfAqMNXddzZUp0VEpLaEvljk7sVAcY2y26O2HfhN8CMiIk1AX/0XEQkJBbqISEgo0EWkWYs32+L69esZMGAA7dq144EHHmjknjU/mpxLRJq1kpIS2rdvz8CBA2vVde7cmRkzZrB48eIm6Fnzoyt0EWl0yZo+t1u3bvTv35+2bds29ik0S7pCF2nJlk2Dz/4zucf8wQ9h2O/iNknW9LlSnQJdRBrdjBkzKCoqAqiaPreiouKYp8+V6hToIi1ZPVfSDSGZ0+dKdbqHLiKNKpnT50p1CnQRaVTJnD73s88+IzMzkwcffJB77rmHzMxMvvgiuUvqpZJ6p89tKJo+V6RpaPrc1NEQ0+eKiEgKUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFpFmLN33u3Llzyc7OJjs7m4EDB7J69epG7l3zoq/+i0izFm/63KysLF577TU6derEsmXLmDRpEu+8804T9LJ50BW6iDS6ZE2fO3DgQDp16gRAXl4ekUikUc+judEVukgLdt+797F+1/qkHvOszmdx0/k3xW3TENPnzpo1i2HDhiXzVFKOAl1EGl2yp8999dVXmTVrFm+++WaD9DdVKNBFWrD6rqQbQrKnz12zZg0TJ05k2bJlZGRkNECPU4fuoYtIo0rm9Ll///vfGTNmDM888wy9evVqnBNoxhToItKokjl97l133cXOnTu5/vrr6du3L7m5MSchbDE0fa5IC6Ppc1OHps8VEWmhFOgiIiGhQBcRCQkFuohISCjQRURCIqFAN7N8M9tgZuVmNi1Ou3Fm5mbWsp8dEhFpAvUGupm1Bh4DhgG9gQlm1jtGuw7Ar4CWO9WZiCRdvOlzlyxZQnZ2dtUz6C39q/+JXKGfD5S7+8fufgCYB4yK0e5u4PfA/iT2T0RauHiBPmTIEFavXs2qVauYPXs2EydObOTeNS+JBPopwJao/UhQVsXMzgW6u/sL8Q5kZpPMrMzMyioqKo65syISDsmaPrd9+/ZV87989dVXxzUXTJgkMjlXrBGq+nqpmbUCHgIK6juQu88EZkLlN0UT66KINJTP7r2Xb9Yld/rcdmefxQ9uuSVum2ROn1tUVMTNN9/M9u3b+ctf/pLUc0k1iVyhR4DuUfuZwLao/Q5AH6DEzDYDecBSfTAqInWZMWMGOTk55OXlVU2fu2LFiuOaPvdnP/sZ69evZ/HixUyfPr0hu93sJXKFXgr0NLMsYCswHvjXo5XuvgfocnTfzEqAKe6uiVpEmrn6rqQbQrKnzz1q0KBBfPTRR+zYsYMuXbrU/4IQqvcK3d0PATcALwLrgAXuvtbM7jKzkQ3dQREJl2ROn1teXs7RCQbfe+89Dhw40KLnRE9ogQt3LwaKa5TdXkfbwd++WyISVvn5+Tz55JNkZ2dz5plnxpw+98iRI3Tr1o2XXnqJESNGMG7cOJYsWcIjjzzCT37yk6pjLVq0iDlz5tC2bVtOPPFE5s+f36I/GNX0uSItjKbPTR2aPldEpIVSoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EWkWYs32+JRpaWltG7dmoULFzZSr5onBbqINGv1Bfrhw4e56aabGDp0aCP2qnlSoItIo0vW9LkAjzzyCGPHjqVbt26NeQrNUkJf/ReRcHpjwUZ2bNmb1GN26d6en1zWK26bZE2fu3XrVoqKili+fDmlpaVJPY9UpEAXkUY3Y8YMioqKAKqmz62oqDjm6XMnT57MfffdR+vWrRu0v6lCgS7SgtV3Jd0Qkjl9bllZGePHjwdgx44dFBcX06ZNG0aPHt0QXW/2dA9dRBpVMqfP/eSTT9i8eTObN29m3LhxPP744y02zEGBLiKNLD8/n0OHDpGdnc306dNjTp+bk5PD5ZdfDsCIESMoKiqq80NR+QdNnyvSwmj63NSh6XNFRFooBbqISEgo0EVEQkKBLtICNdVnZ5K44/k9UqCLtDBpaWns3LlTod6MuTs7d+4kLS3tmF6nLxaJtDCZmZlEIhEqKiqauisSR1paGpmZmcf0GgW6SAvTtm3bqq/XS7jolouISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIZFQoJtZvpltMLNyM5sWo/43Zvahma0xs1fM7J+S31UREYmn3kA3s9bAY8AwoDcwwcx612j2PpDr7tnAQuD3ye6oiIjEl8gV+vlAubt/7O4HgHnAqOgG7v6qu+8LdlcAx/Z9VRER+dYSCfRTgC1R+5GgrC6/AJbFqjCzSWZWZmZlmkdCRCS5Egn0WMtwx5ymzcyuAHKB+2PVu/tMd89199yuXbsm3ksREalXIpNzRYDuUfuZwLaajczsIuBW4J/d/ZvkdE9ERBKVyBV6KdDTzLLM7ARgPLA0uoGZnQs8BYx09+3J76aIiNSn3kB390PADcCLwDpggbuvNbO7zGxk0Ox+oD3wvJmtMrOldRxOREQaSELzobt7MVBco+z2qO2LktwvERE5RvqmqIhISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhoUAXEQkJBbqISEgo0EVEQkKBLiISEgp0EZGQUKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJBToIiIhkVCgm1m+mW0ws3Izmxajvp2ZzQ/q3zGzHsnuqIiIxFdvoJtZa+AxYBjQG5hgZr1rNPsF8Lm7nwE8BNyX7I6KiEh8bRJocz5Q7u4fA5jZPGAU8GFUm1HAHcH2QuBRMzN39yT2FYA//q9bOPj5Ock+rIhIUv0g73Mu+eUNjfqeiQT6KcCWqP0I8KO62rj7ITPbA2QAO6IbmdkkYBLAqaeeelwdbtu+LYd2fXZcrxURaSwndsho9PdMJNAtRlnNK+9E2uDuM4GZALm5ucd19f6vd995PC8TEQm9RD4UjQDdo/YzgW11tTGzNkBHYFcyOigiIolJJNBLgZ5mlmVmJwDjgaU12iwFfh5sjwOWN8T9cxERqVu9t1yCe+I3AC8CrYHZ7r7WzO4Cytx9KTALeMbMyqm8Mh/fkJ0WEZHaErmHjrsXA8U1ym6P2t4PXJrcromIyLHQN0VFREJCgS4iEhIKdBGRkFCgi4iEhDXV04VmVgH813G+vAs1voUq1Wh84tP41E1jE19zGJ9/cveusSqaLNC/DTMrc/fcpu5Hc6XxiU/jUzeNTXzNfXx0y0VEJCQU6CIiIZGqgT6zqTvQzGl84tP41E1jE1+zHp+UvIcuIiK1peoVuoiI1KBAFxEJiZQL9PoWrA4rM5ttZtvN7IOoss5m9pKZbQp+7RSUm5nNCMZojZn1i3rNz4P2m8zs57HeK9WYWXcze9XM1pnZWjP7dVCu8QHMLM3M3jWz1cH43BmUZwWLum8KFnk/ISivc9F3M7s5KN9gZkOb5oySz8xam9n7ZvZCsJ+aY+PuKfND5fS9HwGnAScAq4HeTd2vRjr3QUA/4IOost8D04LtacB9wfZwYBmVK0nlAe8E5Z2Bj4NfOwXbnZr63JIwNicB/YLtDsBGKhc01/hUnpcB7YPttsA7wXkvAMYH5U8C1wXb1wNPBtvjgfnBdu/g71w7ICv4u9i6qc8vSWP0G+A54IVgPyXHJtWu0KsWrHb3A8DRBatDz91fp/YqUKOAPwbbfwRGR5XP8UorgO+Z2UnAUOAld9/l7p8DLwH5Dd/7huXun7r7e8H2l8A6Kte51fgAwXnuDXbbBj8OXEjlou5Qe3yOjttCYIiZWVA+z92/cfdPgHIq/06mNDPLBP4b8L+DfSNFxybVAj3WgtWnNFFfmoPvu/unUBlqQLegvK5xCv34Bf8FPpfKq1CNTyC4pbAK2E7lP1QfAbvd/VDQJPpcqy36Dhxd9D2s4/Mw8O/AkWA/gxQdm1QL9IQWo5Y6xynU42dm7YFFwGR3/yJe0xhloR4fdz/s7n2pXBP4fODsWM2CX1vM+JjZJcB2d18ZXRyjaUqMTaoFeiILVrck/y+4VUDw6/agvK5xCu34mVlbKsN8rrv/n6BY41ODu+8GSqi8h/69YFF3qH6udS36HsbxuQAYaWabqbyFeyGVV+wpOTapFuiJLFjdkkQvzv1zYElU+VXB0xx5wJ7glsOLwL+YWafgiY9/CcpSWnAPcxawzt0fjKrS+ABm1tXMvhdsnwhcROXnDK9Suag71B6fWIu+LwXGB096ZAE9gXcb5ywahrvf7O6Z7t6DyjxZ7u7/nVQdm6b+dPlYf6h8QmEjlfcAb23q/jTief8J+BQ4SOXVwC+ovHf3CrAp+LVz0NaAx4Ix+k8gN+o4/4PKD2zKgaub+rySNDY/pvK/t2uAVcHPcI1P1TllA+8H4/MBcHtQfhqVoVMOPA+0C8rTgv3yoP60qGPdGozbBmBYU59bksdpMP94yiUlx0Zf/RcRCYlUu+UiIiJ1UKCLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFRELi/wO8uyNj0kdOWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "strat = 0\n",
    "plt.plot([0, len(my_simulator.train_actions[:,0])], [twap_stat, twap_stat], 'k--',label = \"Optimal Value\")\n",
    "for i in range(5):\n",
    "    plt.plot(my_simulator._moving_average(my_simulator.train_actions[:,i,strat],n=100),label = \"act \" + str(i))\n",
    "    pass\n",
    "#plt.ylim([0.96,1])\n",
    "#plt.xlim([10000,12000])\n",
    "plt.legend()\n",
    "#plt.plot(moving_average(my_simulator.train_actions[:,0,strat],n=5),label = \"act \" + str(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look at state values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'State values over position')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First check value with position start with 2D\n",
    "from matplotlib import pyplot as plt\n",
    "bar_agent = quentin\n",
    "n = 10\n",
    "values = []\n",
    "x_vals = []\n",
    "my_action = 2\n",
    "t = -1\n",
    "p = 0\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    #action_vals = []\n",
    "    t = 2 * i / (n-1) - 1\n",
    "    state = [p,t] \n",
    "    state = np.reshape(state, [1, 2])\n",
    "    values.append(bar_agent.predict(state)[0][my_action])\n",
    "    x_vals.append(t)\n",
    "    \n",
    "plt.plot(x_vals,values)\n",
    "plt.title(\"State values over position\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating UCB Algo Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Action\n",
      "Predictions:  [0.9973101  0.9973226  0.99733555 0.9973479  0.9973602 ] Variance:  [1.630828336018908e-05, 1.613704688097073e-05, 1.5967720614185055e-05, 1.573529391052375e-05, 1.544295810163021e-05] UCB element:  [0.02556179 0.02542724 0.02529349 0.02510872 0.02487439]\n",
      "Argmax without UCB:  4 Argmax with UCB:  0\n"
     ]
    }
   ],
   "source": [
    "UCB_agent = quentin\n",
    "print(\"Simulating Action\")\n",
    "#md = np.\n",
    "state = [np.array([[1,-1]]),np.array([[[1]] * 32])]\n",
    "#state = np.reshape(state, [1, 2])\n",
    "state1 = [0,0] \n",
    "#state = np.reshape(state, [1, 2])\n",
    "c=250\n",
    "t= 15000\n",
    "\n",
    "predictions = UCB_agent.predict(state)[0]\n",
    "variance = UCB_agent.variance(state)\n",
    "test_ct = c * np.sqrt(np.log(t) / t)\n",
    "ucb_element = test_ct * np.sqrt(variance)\n",
    "print(\"Predictions: \", predictions,\"Variance: \", variance, \"UCB element: \",ucb_element )\n",
    "print(\"Argmax without UCB: \",np.argmax(predictions),\"Argmax with UCB: \",np.argmax(predictions + ucb_element) )\n",
    "#r1 = np.power(UCB_agent.predict_quantiles(state,4),2)\n",
    "#print(UCB_agent.predict(state)[0][4])\n",
    "#print(np.sum(r1)/3 - UCB_agent.predict(state)[0][4]**2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80400574  0.85369796  0.8654276   0.8670649   0.9459648   0.94505507\n",
      "   0.9601302   0.9747751   0.9633708   0.9896604   1.0108677   1.0192543\n",
      "   1.0157591   1.0280389   1.0317265   1.0386562   1.0497516   1.0507549\n",
      "   1.0539684   1.0679046   1.0632467   1.0762932   1.0890766   1.093793\n",
      "   1.1001524   1.126096    1.1394058   1.1440622   1.1951554   1.2517793\n",
      "  15.850747  ]]\n"
     ]
    }
   ],
   "source": [
    "# Try ramping up c\n",
    "print(quentin.predict_quantiles(state,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (3,) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-e234a47fefb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmy_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_rands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,1) and (3,) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "my_rands = np.random.rand(3)\n",
    "#my_rands.shape = (1,3)\n",
    "my_range = np.arange(2)\n",
    "my_range.shape = (2,1)\n",
    "\n",
    "np.cos(np.dot(my_range, my_rands) * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_simulator.show_stats(moving_average = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009993278292196676\n",
      "0.00999727800350609\n",
      "[[7612089.    716650.6   666954.56  679772.75  689112.    671250.25\n",
      "   663567.6 ]]\n"
     ]
    }
   ],
   "source": [
    "print(george.epsilon)\n",
    "print(alice.epsilon)\n",
    "state = [1,0.5] \n",
    "state = np.reshape(state, [1, 2])\n",
    "print(alice.predict(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5.3915353\n",
      "[[5.140569  5.3915353 4.5375085 4.7906394 3.8501995 3.0198317 1.5048974]]\n"
     ]
    }
   ],
   "source": [
    "state = [1,0.5] \n",
    "state = np.reshape(state, [1, 2])\n",
    "pred1 = george.predict(state)\n",
    "pred2 = pred1 + pred1\n",
    "print(np.argmax(pred2))\n",
    "print(pred2[0,np.argmax(pred2)])\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x141e61208>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(moving_average(my_simulator.eval_rewards[:,1],n=300), label  = \"George\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "george.save(\"george1_t50_n7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n",
      "Outer 1:  nan\n",
      "Inner 1:  nan\n",
      "Inner 2:  nan\n",
      "Outer Inner :  nan\n",
      "Outer 2 :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobyweston/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/tobyweston/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#print(my_simulator.code_time[:])\n",
    "#plt.plot(moving_average(my_simulator.code_time[:,0]))\n",
    "print(my_simulator.code_time_o.shape)\n",
    "print(\"Outer 1: \", np.mean(my_simulator.code_time_o[:,0]))\n",
    "print(\"Inner 1: \", np.mean(my_simulator.code_time_i[:,0]))\n",
    "print(\"Inner 2: \", np.mean(my_simulator.code_time_i[:,1]))\n",
    "print(\"Outer Inner : \", np.mean(my_simulator.code_time_o[:,1]))\n",
    "print(\"Outer 2 : \", np.mean(my_simulator.code_time_o[:,2]))\n",
    "#print(np.mean(plt.plot(my_simulator.code_time[:,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14c705630>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_simulator.show_training_stats()\n",
    "#plt.plot(moving_average(my_simulator.all_rewards2,500))\n",
    "plt.plot(moving_average(my_simulator.train_rewards[:,0],n=300), label  = \"Fred\")\n",
    "plt.plot(moving_average(my_simulator.train_rewards[:,1],n=300), label  = \"George\")\n",
    "plt.plot(moving_average(my_simulator.train_rewards[:,2],n=300), label  = \"Tim\")\n",
    "plt.plot(moving_average(my_simulator.train_rewards[:,2],n=300), label  = \"Tim\")\n",
    "plt.legend()\n",
    "#len(my_simulator.all_rewards2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_simulator.show_training_stats()\n",
    "plt.plot(moving_average(my_simulator.all_rewards2,300))\n",
    "\n",
    "len(my_simulator.all_rewards[:,0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_simulator.show_training_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary Area for Simulator Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Todo:**\n",
    "- Saving the agent model\n",
    "- Evaluate agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import reshape\n",
    "#from twap import agent_environment\n",
    "#from matplotlib import pyplot as plt\n",
    "#from numpy import cumsum\n",
    "import time\n",
    "\n",
    "class simulator:\n",
    "\n",
    "    def __init__(self,market_,agents, params = None):\n",
    "        \n",
    "        # Default params\n",
    "        if params is None:\n",
    "            params = params = {\"terminal\" : 1, \"num_trades\" : 50, \"position\" : 10, \"batch_size\" : 32 }\n",
    "            print(\"Initialising using default parameters\")\n",
    "\n",
    "        self.terminal = params[\"terminal\"]\n",
    "        self.num_steps = params[\"num_trades\"]\n",
    "        self.batch_size = params[\"batch_size\"]\n",
    "        self.agents = agents\n",
    "        self.n_agents = len(self.agents)\n",
    "\n",
    "        self.m = market_\n",
    "        self.env = agent_environmentM(self.m,\n",
    "                                     params[\"position\"],\n",
    "                                     params[\"num_trades\"],\n",
    "                                     params[\"terminal\"],\n",
    "                                     [0,0.001,0.005,0.01,0.02,0.05,0.1],\n",
    "                                     self.n_agents\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "\n",
    "        # Stats\n",
    "        self.final_timestep = []\n",
    "        self.train_rewards = np.zeros((0,self.n_agents))\n",
    "        self.eval_rewards = np.zeros((0,self.n_agents))\n",
    "        \n",
    "        \n",
    "\n",
    "    def __moving_average(self,a, n=300):\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "\n",
    "\n",
    "\n",
    "    def train(self,n_episodes = 10000, epsilon = None, epsilon_decay = None,show_details = True, evaluate = False):\n",
    "\t\t# TODO: different training parameters\n",
    "        \n",
    "        # Number of agents to be trained\n",
    "        \n",
    "        ### Live Plots ###\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        plt.ion()\n",
    "\n",
    "        fig.show()\n",
    "        fig.canvas.draw()\n",
    "        ### Live Plots ###\n",
    "        \n",
    "        # Default training parameters if not provided\n",
    "        if epsilon is None:\n",
    "            epsilon = [1] * self.n_agents\n",
    "            \n",
    "        if epsilon_decay is None:\n",
    "            epsilon_decay = [0.998] * self.n_agents\n",
    "        \n",
    "        if evaluate:\n",
    "            train = [False] * self.n_agents\n",
    "        else:\n",
    "            train = [True] * self.n_agents\n",
    "            \n",
    "        # TEMPORARY? #\n",
    "        self.code_time_i = np.zeros((0,2))\n",
    "        self.code_time_o = np.zeros((0,3))\n",
    "        # TEMPORARY? #\n",
    "\n",
    "        # Evaluatory Stats\n",
    "        current_training_step = len(self.train_rewards) #\n",
    "        \n",
    "        n_correct = 0#\n",
    "        total_reward = np.zeros(self.n_agents)#\n",
    "        \n",
    "        pcnt_opt = []#\n",
    "        \n",
    "        \n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t# Set up the agents:\n",
    "        for i ,agent in enumerate(self.agents):\n",
    "            agent.epsilon = epsilon[i]\n",
    "            agent.epsilon_decay = epsilon_decay[i]\n",
    "            \n",
    "        # Setup action list\n",
    "        actions = [-1] * self.n_agents\n",
    "        \n",
    "        timer_o = []\n",
    "        \n",
    "        for e in range(n_episodes): # iterate over new episodes of the game\n",
    "            \n",
    "            #Time code\n",
    "            timer = []\n",
    "            timer_o = []\n",
    "            start_time_o = time.time()\n",
    "            \n",
    "            states = self.env.reset() # reset state at start of each new episode of the game\n",
    "            states = np.reshape(states, [self.n_agents,1, self.env.state_size])\n",
    "            \n",
    "            correct_action = 0.0\n",
    "            \n",
    "            done = np.zeros(self.n_agents) # Has the episode finished\n",
    "            inactive = np.zeros(self.n_agents) # Agents which are still trading\n",
    "            \n",
    "            total_reward.fill(0)\n",
    "            \n",
    "            time_now = time.time()\n",
    "            timer_o.append(time_now - start_time_o)\n",
    "            start_time_o = time.time()\n",
    "            \n",
    "            \n",
    "            for t in range(self.num_steps):\n",
    "                timer = []\n",
    "                start_time = time.time()\n",
    "                # Get actions for each agent\n",
    "                for i, agent in enumerate(self.agents):\n",
    "                    # Agents action only updated if still active\n",
    "                    if not inactive[i]:\n",
    "                        actions[i] = agent.act(states[i])\n",
    "                \n",
    "                next_states, rewards, done = self.env.step(actions)\n",
    "                \n",
    "                time_now = time.time()\n",
    "                timer.append(time_now - start_time)\n",
    "                start_time = time_now\n",
    "                \n",
    "                rewards = (1 - done) * rewards\n",
    "                \n",
    "                next_states = np.reshape(next_states, [self.n_agents,1, self.env.state_size])\n",
    "                total_reward += rewards\n",
    "                #print(total_reward)\n",
    "                for i, agent in enumerate(self.agents):\n",
    "                    if not inactive[i] and train[i]:\n",
    "                        agent.remember(states[i], actions[i], rewards[i], next_states[i], done[i])\n",
    "                \n",
    "                time_now = time.time()\n",
    "                timer.append(time_now - start_time)\n",
    "                #if e % 100 == 0:\n",
    "                    #print(\"time\", t, \"Actions \", actions[0], \"Rewards \", rewards[0], states[0],next_states[0])\n",
    "\n",
    "                states = next_states\n",
    "                \n",
    "                if actions[0] == 4:\n",
    "                    correct_action += 1\n",
    "                    \n",
    "                    \n",
    "                if all(done): \n",
    "                    percent_optimal = correct_action / self.num_steps\n",
    "                    pcnt_opt.append(percent_optimal)\n",
    "                    break # exit loop\n",
    "                    \n",
    "                inactive = inactive + done\n",
    "                \n",
    "                self.code_time_i = np.vstack((self.code_time_i,timer))   \n",
    "\n",
    "            if not all(done):\n",
    "                print(\"We have a problem.\")\n",
    "                \n",
    "            \n",
    "            time_now = time.time()\n",
    "            timer_o.append(time_now - start_time_o)\n",
    "            start_time_o = time.time()\n",
    "            \n",
    "            if evaluate:\n",
    "                self.eval_rewards = np.vstack((self.eval_rewards,total_reward))\n",
    "            else:\n",
    "                self.train_rewards = np.vstack((self.train_rewards,total_reward))\n",
    "            \n",
    "            for i, agent in enumerate(self.agents):\n",
    "                if len(agent.memory) > self.batch_size and train[i]:\n",
    "                    agent.replay(self.batch_size) # train the agent by replaying the experiences of the episode\n",
    "\n",
    "            time_now = time.time()\n",
    "            timer_o.append(time_now - start_time_o)\n",
    "            self.code_time_o = np.vstack((self.code_time_o,timer_o)) \n",
    "            if e % 100 == 0:\n",
    "                #self.total_training_steps += 100\n",
    "                if show_details and not evaluate:\n",
    "                    ax.clear()\n",
    "                    for i in range(self.train_rewards.shape[1]):\n",
    "                        ax.plot(self.__moving_average(self.train_rewards[current_training_step:,i],n=500), label  = self.agents[i].agent_name)\n",
    "                    plt.pause(0.0001)\n",
    "                    plt.draw()\n",
    "        if not evaluate:\n",
    "            self.show_stats(trained_from = current_training_step)\t\t\n",
    "        \n",
    "    def evaluate(self,n_episodes = 500):\n",
    "        start_iteration = len(self.eval_rewards)\n",
    "        epsilon = [0] * self.n_agents\n",
    "        self.train(n_episodes = n_episodes, epsilon = epsilon, show_details = False,evaluate = True)\n",
    "        self.show_stats(trained_from = start_iteration,training = False)\n",
    "\n",
    "    def show_stats(self,trained_from = 0,trained_to = None,moving_average = 400,training = True):\n",
    "        \n",
    "        if training:\n",
    "            if trained_to is None:\n",
    "                trained_to = len(self.train_rewards)\n",
    "            for i in range(self.train_rewards.shape[1]):\n",
    "                plt.plot(self.__moving_average(self.train_rewards[trained_from:trained_to,i],n=moving_average), label  = self.agents[i].agent_name)\n",
    "        else:\n",
    "            if trained_to is None:\n",
    "                trained_to = len(self.eval_rewards)\n",
    "            for i in range(self.eval_rewards.shape[1]):\n",
    "                plt.plot(self.__moving_average(self.eval_rewards[trained_from:trained_to,i],n=moving_average), label  = self.agents[i].agent_name)\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "    #def test_convergence(self,)\n",
    "\n",
    "    def execute(self,agent):\n",
    "        # Currently just one strat\n",
    "        position = []\n",
    "        cash = []\n",
    "        states = self.env.reset() # reset state at start of each new episode of the game\n",
    "        states = np.reshape(states, [len(training_agents),1, self.env.state_size])\n",
    "            \n",
    "        for t in range(self.num_steps):\n",
    "\n",
    "            action = agent.act(states)\n",
    "            next_state, reward, done = self.env.step(action)\n",
    "            next_states = np.reshape(next_states, [len(training_agents),1, self.env.state_size])\n",
    "            total_reward += rewards\n",
    "            #print(total_reward)\n",
    "            for i, agent in enumerate(training_agents):\n",
    "                # Note this happens when its been done for more than one step\n",
    "                training_agents[agent].remember(states[i], actions[i], rewards[i], next_states[i], done[i])\n",
    "            states = next_states\n",
    "\n",
    "            if all(done): \n",
    "                break \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-82718a3ca1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0msimple_stock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs_stock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# No drift, 0.5 vol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0msimple_market\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_stock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_market\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 6 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "action_values = np.array([1,2,3,4,5,6,7,8])\n",
    "actions = np.ones(3,dtype = int)\n",
    "print(actions)\n",
    "print(action_values[list(actions)])\n",
    "\n",
    "volumes = np.array([1,2,1,4,5,6],dtype = float)\n",
    "position = np.array([5,5,5,5,4,5],dtype = float)\n",
    "\n",
    "position -= np.minimum(volumes,position)\n",
    "time = 0.647\n",
    "\n",
    "\n",
    "times = np.ones(len(position)) * time\n",
    "\n",
    "\n",
    "print(position,times)\n",
    "state = np.vstack((position,times))\n",
    "\n",
    "\n",
    "\n",
    "print(state.T)\n",
    "done = np.zeros(6)\n",
    "print(done.T)\n",
    "done.shape = (6,1)\n",
    "print(done)\n",
    "\n",
    "state = np.array(state,dtype = 'object')\n",
    "done = np.array(done,dtype = 'object')\n",
    "\n",
    "\n",
    "print(state.T,done)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "simple_stock = bs_stock(1,0,0.1) # No drift, 0.5 vol\n",
    "simple_market = market(simple_stock,3)\n",
    "env = agent_environment(simple_market,10,50,1,[0,0.001,0.005,0.01,0.02,0.05,0.1],3)\n",
    "print(env.reset())\n",
    "states, rewards, done = env.step([1,1,1])\n",
    "\n",
    "states = np.reshape(states, [3,1, 2])\n",
    "print(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import gauss\n",
    "from numpy import exp\n",
    "from numpy import ones\n",
    "from numpy import vectorize\n",
    "\n",
    "class stock:\n",
    "\t\n",
    "\tdef __init__(self, initial, drift, vol):\n",
    "\t\tself.initial = initial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class bs_stock:\n",
    "\n",
    "\tdef __init__(self, initial, drift, vol):\n",
    "\t\tself.initial = initial\n",
    "\t\tself.price = initial\n",
    "\t\tself.drift = drift\n",
    "\t\tself.vol = vol\n",
    "\n",
    "\tdef generate_price(self,dt,St = None):\n",
    "\t\tif St is None:\n",
    "\t\t\tSt = self.price\n",
    "\n",
    "\t\tself.price = St * exp((self.drift - 0.5 * self.vol) * dt + self.vol * dt**0.5 * gauss(0,1))\n",
    "\t\treturn self.price\n",
    "\n",
    "\tdef generate_path(self,T,grid_size):\n",
    "\t\tres = []\n",
    "\t\tself.reset()\n",
    "\t\tnext_price = self.price\n",
    "\t\tres.append(next_price)\n",
    "\t\tdt = T / grid_size\n",
    "\n",
    "\t\tfor i in range(grid_size):\n",
    "\t\t\tnext_price = generate_price(dt)\n",
    "\t\t\tres.append(next_price)\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.price = self.initial\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\tprint(f\"Stock Price: {self.price} \\n \\\n",
    "\t\t Black Scholes Dynamics, drift: {self.drift}, vol: {self.vol}\")\n",
    "\n",
    "\n",
    "class marketM:\n",
    "\t'''Basic market model, base class for more complex models'''\n",
    "\n",
    "\tdef __init__(self,stock_,num_strats = 1):\n",
    "\t\tself.stock = stock_\n",
    "\t\tself.spread = 0\n",
    "\t\tself.price_adjust = ones(num_strats)\n",
    "\n",
    "\n",
    "\tdef sell(self,volume,dt):\n",
    "\t\t'''sell *volume* of stock over time window dt, volume is np array'''\n",
    "\t\tself.price_adjust *= vectorize(self.exp_g)(volume)\n",
    "\t\t#print(\"volume \", volume, \"price_adjust \",self.price_adjust)        \n",
    "\t\tret = (self.stock.price * self.price_adjust - vectorize(self.f)(volume/dt) - 0.5 * self.spread) * volume \n",
    "\t\treturn ret\n",
    "\n",
    "\n",
    "\tdef g(self,v):\n",
    "\t\treturn v * 0.001\n",
    "    \n",
    "\tdef exp_g(self,v):\n",
    "\t\treturn exp(-self.g(v))\n",
    "\n",
    "\tdef f(self,v):\n",
    "\t\treturn v * 0.001\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.stock.reset()\n",
    "\t\tself.price_adjust = ones(len(self.price_adjust))\n",
    "\n",
    "\tdef progress(self,dt):\n",
    "\t\tself.stock.generate_price(dt)\n",
    "\n",
    "\tdef state(self):\n",
    "\t\treturn (self.stock.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "    \n",
    "class agent_environmentM:\n",
    "\n",
    "    def __init__(self, market, position,num_steps,terminal,action_values_pct,n_strats):\n",
    "        self.m = market\n",
    "        self.initial = np.ones(n_strats) * position\n",
    "        self.n_strats = n_strats\n",
    "        self.reset()\n",
    "        self.terminal = terminal\n",
    "        self.step_size = terminal / num_steps\n",
    "        # Possible amounts to sell: 0 - 10% of the total position\n",
    "        self.action_values = np.array(action_values_pct) * position \n",
    "        self.num_actions = len(self.action_values)\n",
    "        self.state_size = 2\n",
    "\n",
    "\n",
    "    def sell(self,volumes):\n",
    "        capped_volume = np.minimum(volumes,self.position)\n",
    "        self.position -= capped_volume\n",
    "        returns = self.m.sell(capped_volume,self.step_size) \n",
    "        self.cash += returns\n",
    "        return returns\n",
    "\n",
    "    def reset(self):\n",
    "        self.position = self.initial.copy()\n",
    "        self.cash = np.zeros(self.n_strats)\n",
    "        self.time = 0\n",
    "        self.m.reset()\n",
    "        return self.state() # State not dynamic (full = False)\n",
    "\n",
    "    def progress(self,dt):\n",
    "        self.m.progress(dt)\n",
    "        self.time += dt\n",
    "\n",
    "    def state(self,full = False):\n",
    "\n",
    "        times = np.ones(self.n_strats) * self.time\n",
    "        # TODO: Store state as a seprate variable\n",
    "        states = np.vstack((self.position,times))\n",
    "        \n",
    "        return np.vstack((self.position,times)).T\n",
    "    \n",
    "    def step(self,actions):\n",
    "        self.progress(self.step_size)\n",
    "        \n",
    "        rewards = self.sell(self.action_values[actions])\n",
    "        done = (self.position == 0) + (self.time >= self.terminal)\n",
    "        done = np.array(done,dtype = bool)\n",
    "            \n",
    "\t\t# Reward is currently just the returned cash / 100...\n",
    "\t\t# Not sure what the last value of the tuple should be??\n",
    "        \n",
    "        # Ufortunately this is no longer the format of the AI gym env\n",
    "        # Ideally this would be flexible depending on the input (array vs scalar)\n",
    "        return self.state(), rewards, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_dir = 'model_output/trading/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_time_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 7\n"
     ]
    }
   ],
   "source": [
    "my_stock = bs_stock(1,0,0.1) # No drift, 0.5 vol\n",
    "mkt = market(my_stock)\n",
    "env = agent_environment(mkt,10,number_time_steps,1)\n",
    "twap_mkt = market(my_stock)\n",
    "twap_env = agent_environment(twap_mkt,10,number_time_steps,1)\n",
    "action_size = env.num_actions\n",
    "n_episodes = 12000\n",
    "state_size = 2\n",
    "print(state_size,action_size)\n",
    "fred = DQNAgent(state_size, action_size,\"Jack\") # initialise agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get TWAP stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_episodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a0534f52de5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate over new episodes of the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwap_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset state at start of each new episode of the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_episodes' is not defined"
     ]
    }
   ],
   "source": [
    "all_rewards =[]\n",
    "optimal_action = 4\n",
    "\n",
    "\n",
    "\n",
    "done = False\n",
    "for e in range(n_episodes): # iterate over new episodes of the game\n",
    "    state = twap_env.reset() # reset state at start of each new episode of the game\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    \n",
    "    correct_action = 0\n",
    "    total_reward = 0.0\n",
    "    \n",
    "    for time in range(number_time_steps):  \n",
    "        action = 4\n",
    "        # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position:\n",
    "        next_state, reward, done, _ = twap_env.step(action)\n",
    "        reward = reward if not done else 0 # reward +1 for each additional frame with pole upright        \n",
    "        total_reward += reward\n",
    "        \n",
    "        # Evaluation\n",
    "        if action == optimal_action:\n",
    "            correct_action += 1\n",
    "        if done: \n",
    "            percent_optimal = correct_action / number_time_steps\n",
    "            all_rewards.append(total_reward)\n",
    "            #print(\"episode: {}/{}, score: {}, e: {:.2}, reward: {:.2}\" # print the episode's score and agent's epsilon\n",
    "                  #.format(e, n_episodes, percent_optimal, 0.0, total_reward))\n",
    "            break # exit loop\n",
    "print(\"Average reward: \", np.mean(all_rewards))\n",
    "twap_stat = np.mean(all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99 0.  ]\n",
      " [9.99 0.  ]\n",
      " [9.99 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())\n",
    "agent = fred\n",
    "e = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE DIM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import os # for creating directories\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, agent_name):\n",
    "        self.agent_name = agent_name\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        # double-ended queue; acts like list, but elements can be added/removed from either end:\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        # decay or discount rate: enables agent to take into account future actions in addition\n",
    "        # to the immediate ones, but discounted at this rate:\n",
    "        self.gamma = 1 # Was 0.95\n",
    "        # exploration rate: how much to act randomly; more initially than later due to epsilon\n",
    "        # decay:\n",
    "        self.epsilon = 1.0\n",
    "        # decrease number of random explorations as the agent's performance (hopefully)\n",
    "        # improves over time:\n",
    "        self.epsilon_decay = 0.998 \n",
    "        # minimum amount of random exploration permitted:\n",
    "        self.epsilon_min = 0.01\n",
    "        # rate at which NN adjusts models parameters via SGD to reduce cost:\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(5, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(5, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # list of previous experiences, enabling re-training later\n",
    "        #print(\"State \", state, \"Action \", action, \"Reward \", reward, \"next state \", next_state, \"done\", done)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # if acting randomly, take random action:\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        # if not acting randomly, predict reward value based on current state:\n",
    "        act_values = self.model.predict(state)\n",
    "        # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    # method that trains NN with experiences sampled from memory:\n",
    "    def replay(self, batch_size):\n",
    "        # sample a minibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        # extract data for each minibatch sample:\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward:\n",
    "            target = reward\n",
    "\n",
    "            # if not done, then predict future discounted reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            #print(\"state\", state, \"reward: \", reward, \"done \", done, \"predict \", self.model.predict(next_state)[0])\n",
    "            target_f[0][action] = target\n",
    "            # Change the action taken to the reward + predicted max of next states\n",
    "            # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat:\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, file_name):\n",
    "        self.model.load_weights(file_name)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.model.save_weights(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    \"terminal\" : 1,\n",
    "    \"num_trades\" : 50,\n",
    "    \"position\" : 10,\n",
    "    \"batch_size\" : 32\n",
    "}\n",
    "number_time_steps = 50\n",
    "state_size = 2\n",
    "from market_models import market\n",
    "from twap import agent_environment\n",
    "from market_models import bs_stock\n",
    "from twap import agent_environment\n",
    "\n",
    "simple_stock = bs_stock(1,0,0.1) # No drift, 0.5 vol\n",
    "simple_market = market(simple_stock,num_strats = 1)\n",
    "\n",
    "state_size = 2\n",
    "action_size = 7 # This is NOT dynamic (and probably should be)\n",
    "\n",
    "#fred = DQNAgent(state_size, action_size,\"Fred\") # initialise agent\n",
    "\n",
    "env = agent_environment(simple_market,\n",
    "                                     params[\"position\"],\n",
    "                                     params[\"num_trades\"],\n",
    "                                     params[\"terminal\"],\n",
    "                                     [0,0.001,0.005,0.01,0.02,0.05,0.1]\n",
    "                                    )\n",
    "agent = alice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2\n",
      "10 [0, 0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
      "State  [[9.   0.02]] Action  6 Reward  [0.94177681] Stock  0.9927690821008861\n",
      "State  [[8.99 0.04]] Action  1 Reward  [0.0098443] Stock  0.9859255280437625\n",
      "State  [[8.79 0.06]] Action  4 Reward  [0.18774377] Stock  0.9498674718483238\n",
      "State  [[8.59 0.08]] Action  4 Reward  [0.18529801] Stock  0.9378114556775721\n",
      "State  [[8.39 0.1 ]] Action  4 Reward  [0.18166391] Stock  0.91979925500815\n",
      "State  [[8.19 0.12]] Action  4 Reward  [0.18094335] Stock  0.9163738793134334\n",
      "State  [[7.99 0.14]] Action  4 Reward  [0.17793669] Stock  0.9014936296887037\n",
      "State  [[7.89 0.16]] Action  3 Reward  [0.08954958] Stock  0.9023978584743934\n",
      "State  [[7.69 0.18]] Action  4 Reward  [0.18322727] Stock  0.9282781961274605\n",
      "State  [[7.49 0.2 ]] Action  4 Reward  [0.18035429] Stock  0.9140628567600129\n",
      "State  [[7.48 0.22]] Action  1 Reward  [0.00903821] Stock  0.9066030039708823\n",
      "State  [[7.28 0.24]] Action  4 Reward  [0.17855983] Stock  0.9052580835064212\n",
      "State  [[7.08 0.26]] Action  4 Reward  [0.17871923] Stock  0.9062385076548723\n",
      "State  [[7.03 0.28]] Action  2 Reward  [0.04384499] Stock  0.8820154490236081\n",
      "State  [[6.83 0.3 ]] Action  4 Reward  [0.17489055] Stock  0.8872609251446688\n",
      "State  [[6.63 0.32]] Action  4 Reward  [0.17801681] Stock  0.9031224266287174\n",
      "State  [[5.63 0.34]] Action  6 Reward  [0.8739471] Stock  0.927993587014871\n",
      "State  [[5.13 0.36]] Action  5 Reward  [0.44045497] Stock  0.9103324800955671\n",
      "State  [[4.13 0.38]] Action  6 Reward  [0.85317138] Stock  0.9084885867833719\n",
      "State  [[3.63 0.4 ]] Action  5 Reward  [0.44470852] Stock  0.9202604738801952\n",
      "State  [[3.13 0.42]] Action  5 Reward  [0.44839103] Stock  0.9281365148666567\n",
      "State  [[3.08 0.44]] Action  2 Reward  [0.04624887] Stock  0.9339177721682722\n",
      "State  [[2.58 0.46]] Action  5 Reward  [0.45695294] Stock  0.945898466886887\n",
      "State  [[2.08 0.48]] Action  5 Reward  [0.44565638] Stock  0.9235987716510692\n",
      "State  [[1.58 0.5 ]] Action  5 Reward  [0.44586752] Stock  0.9244865325373698\n",
      "State  [[1.08 0.52]] Action  5 Reward  [0.43572474] Stock  0.9044815765086447\n",
      "State  [[0.58 0.54]] Action  5 Reward  [0.43692297] Stock  0.9073530674511235\n",
      "State  [[0.08 0.56]] Action  5 Reward  [0.43215554] Stock  0.8981769533303491\n",
      "State  [[0.   0.58]] Action  5 Reward  0 Stock  0.883068518425511\n"
     ]
    }
   ],
   "source": [
    "state = env.reset() # reset state at start of each new episode of the game\n",
    "state = np.reshape(state, [1, state_size])\n",
    "print(env.position)\n",
    "print(state_size)\n",
    "print(env.position,env.action_values)\n",
    "    \n",
    "correct_action = 0\n",
    "optimal_action = 3\n",
    "\n",
    "for time in range(number_time_steps):  \n",
    "    action = agent.act(state)\n",
    "    # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position:\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    reward = reward if not done else 0 # reward +1 for each additional frame with pole upright        \n",
    "    next_state = np.reshape(next_state, [1, state_size]) # TRY REMOVING\n",
    "        \n",
    "    # remember the previous timestep's state, actions, reward, etc.:\n",
    "    #agent.remember(state, action, reward, next_state, done)\n",
    "    # set \"current state\" for upcoming iteration to the current next state:\n",
    "    state = next_state\n",
    "        \n",
    "    print(\"State \",state,\"Action \",action,\"Reward \", reward, \"Stock \", env.m.stock.price)\n",
    "        \n",
    "    # Evaluation\n",
    "    if action == optimal_action:\n",
    "        correct_action += 1\n",
    "    if done: \n",
    "        percent_optimal = correct_action / number_time_steps\n",
    "        #print(\"episode: {}/{}, score: {}, e: {:.2}\" # print the episode's score and agent's epsilon\n",
    "                  #.format(e, n_episodes, percent_optimal, agent.epsilon))\n",
    "        break # exit loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to become a seperate evaluate class, producing stats of performance over time relative to baseline.\n",
    "\n",
    "May need to split $g(\\cdot)$ out of the stock price so seperate strats can be evaluated simaltaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/10000, score: 0.08, e: 0.998, reward: [9.40352391]\n",
      "episode: 0/10000, score: 0.08, e: 0.998, reward: [9.40352391]\n",
      "episode: 50/10000, score: 0.12, e: 0.9029373243680279, reward: [8.81362216]\n",
      "episode: 50/10000, score: 0.12, e: 0.9029373243680279, reward: [8.81362216]\n",
      "episode: 100/10000, score: 0.08, e: 0.8169296710790511, reward: [8.70349158]\n",
      "episode: 100/10000, score: 0.08, e: 0.8169296710790511, reward: [8.70349158]\n",
      "episode: 150/10000, score: 0.06, e: 0.7391145204418551, reward: [9.35133596]\n",
      "episode: 150/10000, score: 0.06, e: 0.7391145204418551, reward: [9.35133596]\n",
      "episode: 200/10000, score: 0.08, e: 0.6687115105103473, reward: [8.36707224]\n",
      "episode: 200/10000, score: 0.08, e: 0.6687115105103473, reward: [8.36707224]\n",
      "episode: 250/10000, score: 0.02, e: 0.6050146112969089, reward: [9.31593255]\n",
      "episode: 250/10000, score: 0.02, e: 0.6050146112969089, reward: [9.31593255]\n",
      "episode: 300/10000, score: 0.1, e: 0.5473850444168268, reward: [8.65049381]\n",
      "episode: 300/10000, score: 0.1, e: 0.5473850444168268, reward: [8.65049381]\n",
      "episode: 350/10000, score: 0.0, e: 0.49524487715912174, reward: [8.50193025]\n",
      "episode: 350/10000, score: 0.0, e: 0.49524487715912174, reward: [8.50193025]\n",
      "episode: 400/10000, score: 0.36, e: 0.448071226742515, reward: [8.26172988]\n",
      "episode: 400/10000, score: 0.36, e: 0.448071226742515, reward: [8.26172988]\n",
      "episode: 450/10000, score: 0.02, e: 0.40539101663445526, reward: [9.66005052]\n",
      "episode: 450/10000, score: 0.02, e: 0.40539101663445526, reward: [9.66005052]\n",
      "episode: 500/10000, score: 0.04, e: 0.36677623234744455, reward: [9.90358916]\n",
      "episode: 500/10000, score: 0.04, e: 0.36677623234744455, reward: [9.90358916]\n",
      "episode: 550/10000, score: 0.02, e: 0.3318396291358591, reward: [8.90428573]\n",
      "episode: 550/10000, score: 0.02, e: 0.3318396291358591, reward: [8.90428573]\n",
      "episode: 600/10000, score: 0.22, e: 0.3002308485483078, reward: [9.90661113]\n",
      "episode: 600/10000, score: 0.22, e: 0.3002308485483078, reward: [9.90661113]\n",
      "episode: 650/10000, score: 0.06, e: 0.2716329048907331, reward: [2.71439547]\n",
      "episode: 650/10000, score: 0.06, e: 0.2716329048907331, reward: [2.71439547]\n",
      "episode: 700/10000, score: 0.0, e: 0.24575900636508355, reward: [9.04180919]\n",
      "episode: 700/10000, score: 0.0, e: 0.24575900636508355, reward: [9.04180919]\n",
      "episode: 750/10000, score: 0.04, e: 0.2223496790046429, reward: [8.78872314]\n",
      "episode: 750/10000, score: 0.04, e: 0.2223496790046429, reward: [8.78872314]\n",
      "episode: 800/10000, score: 0.4, e: 0.20117016456366946, reward: [10.42973634]\n",
      "episode: 800/10000, score: 0.4, e: 0.20117016456366946, reward: [10.42973634]\n",
      "episode: 850/10000, score: 0.0, e: 0.18200806626632815, reward: [9.01780397]\n",
      "episode: 850/10000, score: 0.0, e: 0.18200806626632815, reward: [9.01780397]\n",
      "episode: 900/10000, score: 0.02, e: 0.16467121880552807, reward: [8.42442746]\n",
      "episode: 900/10000, score: 0.02, e: 0.16467121880552807, reward: [8.42442746]\n",
      "episode: 950/10000, score: 0.02, e: 0.14898576123114782, reward: [9.12137029]\n",
      "episode: 950/10000, score: 0.02, e: 0.14898576123114782, reward: [9.12137029]\n",
      "episode: 1000/10000, score: 0.12, e: 0.13479439340178997, reward: [9.56291068]\n",
      "episode: 1000/10000, score: 0.12, e: 0.13479439340178997, reward: [9.56291068]\n",
      "episode: 1050/10000, score: 0.0, e: 0.12195479851505375, reward: [9.80041984]\n",
      "episode: 1050/10000, score: 0.0, e: 0.12195479851505375, reward: [9.80041984]\n",
      "episode: 1100/10000, score: 0.02, e: 0.11033821589681822, reward: [6.41732635]\n",
      "episode: 1100/10000, score: 0.02, e: 0.11033821589681822, reward: [6.41732635]\n",
      "episode: 1150/10000, score: 0.0, e: 0.09982814973688857, reward: [10.06983478]\n",
      "episode: 1150/10000, score: 0.0, e: 0.09982814973688857, reward: [10.06983478]\n",
      "episode: 1200/10000, score: 0.0, e: 0.09031920082168032, reward: [8.90492314]\n",
      "episode: 1200/10000, score: 0.0, e: 0.09031920082168032, reward: [8.90492314]\n",
      "episode: 1250/10000, score: 0.12, e: 0.08171600954808274, reward: [9.3733955]\n",
      "episode: 1250/10000, score: 0.12, e: 0.08171600954808274, reward: [9.3733955]\n",
      "episode: 1300/10000, score: 0.02, e: 0.0739322996186152, reward: [9.60535472]\n",
      "episode: 1300/10000, score: 0.02, e: 0.0739322996186152, reward: [9.60535472]\n",
      "episode: 1350/10000, score: 0.12, e: 0.06689001282766313, reward: [8.01153048]\n",
      "episode: 1350/10000, score: 0.12, e: 0.06689001282766313, reward: [8.01153048]\n",
      "episode: 1400/10000, score: 0.08, e: 0.06051852626207736, reward: [9.22456364]\n",
      "episode: 1400/10000, score: 0.08, e: 0.06051852626207736, reward: [9.22456364]\n",
      "episode: 1450/10000, score: 0.0, e: 0.054753944065908174, reward: [9.30319798]\n",
      "episode: 1450/10000, score: 0.0, e: 0.054753944065908174, reward: [9.30319798]\n",
      "episode: 1500/10000, score: 0.12, e: 0.04953845666680137, reward: [9.64913285]\n",
      "episode: 1500/10000, score: 0.12, e: 0.04953845666680137, reward: [9.64913285]\n",
      "episode: 1550/10000, score: 0.02, e: 0.044819761038119355, reward: [9.57168344]\n",
      "episode: 1550/10000, score: 0.02, e: 0.044819761038119355, reward: [9.57168344]\n",
      "episode: 1600/10000, score: 0.08, e: 0.04055053618293973, reward: [9.86876212]\n",
      "episode: 1600/10000, score: 0.08, e: 0.04055053618293973, reward: [9.86876212]\n",
      "episode: 1650/10000, score: 0.0, e: 0.03668796857987223, reward: [8.91085144]\n",
      "episode: 1650/10000, score: 0.0, e: 0.03668796857987223, reward: [8.91085144]\n",
      "episode: 1700/10000, score: 0.0, e: 0.03319332283167145, reward: [9.04348034]\n",
      "episode: 1700/10000, score: 0.0, e: 0.03319332283167145, reward: [9.04348034]\n",
      "episode: 1750/10000, score: 0.06, e: 0.030031553210935435, reward: [9.34583517]\n",
      "episode: 1750/10000, score: 0.06, e: 0.030031553210935435, reward: [9.34583517]\n",
      "episode: 1800/10000, score: 0.16, e: 0.02717095220731272, reward: [9.70430429]\n",
      "episode: 1800/10000, score: 0.16, e: 0.02717095220731272, reward: [9.70430429]\n",
      "episode: 1850/10000, score: 0.0, e: 0.02458283255170592, reward: [5.29536379]\n",
      "episode: 1850/10000, score: 0.0, e: 0.02458283255170592, reward: [5.29536379]\n",
      "episode: 1900/10000, score: 0.0, e: 0.022241239528681966, reward: [8.84499818]\n",
      "episode: 1900/10000, score: 0.0, e: 0.022241239528681966, reward: [8.84499818]\n",
      "episode: 1950/10000, score: 0.0, e: 0.020122690692040587, reward: [9.87651776]\n",
      "episode: 1950/10000, score: 0.0, e: 0.020122690692040587, reward: [9.87651776]\n",
      "episode: 2000/10000, score: 0.0, e: 0.018205940373303156, reward: [5.87516467]\n",
      "episode: 2000/10000, score: 0.0, e: 0.018205940373303156, reward: [5.87516467]\n",
      "episode: 2050/10000, score: 0.12, e: 0.016471766621517243, reward: [9.8336942]\n",
      "episode: 2050/10000, score: 0.12, e: 0.016471766621517243, reward: [9.8336942]\n",
      "episode: 2100/10000, score: 0.32, e: 0.014902778437722815, reward: [9.15663316]\n",
      "episode: 2100/10000, score: 0.32, e: 0.014902778437722815, reward: [9.15663316]\n",
      "episode: 2150/10000, score: 0.0, e: 0.01348324137094887, reward: [10.39784947]\n",
      "episode: 2150/10000, score: 0.0, e: 0.01348324137094887, reward: [10.39784947]\n",
      "episode: 2200/10000, score: 0.0, e: 0.012198919726746358, reward: [9.79952128]\n",
      "episode: 2200/10000, score: 0.0, e: 0.012198919726746358, reward: [9.79952128]\n",
      "episode: 2250/10000, score: 0.0, e: 0.01103693380586043, reward: [8.68358146]\n",
      "episode: 2250/10000, score: 0.0, e: 0.01103693380586043, reward: [8.68358146]\n",
      "episode: 2300/10000, score: 0.0, e: 0.009985630741373389, reward: [9.4030932]\n",
      "episode: 2300/10000, score: 0.0, e: 0.009985630741373389, reward: [9.4030932]\n",
      "episode: 2350/10000, score: 0.0, e: 0.009985630741373389, reward: [9.90268206]\n",
      "episode: 2350/10000, score: 0.0, e: 0.009985630741373389, reward: [9.90268206]\n",
      "episode: 2400/10000, score: 0.0, e: 0.009985630741373389, reward: [9.47624126]\n",
      "episode: 2400/10000, score: 0.0, e: 0.009985630741373389, reward: [9.47624126]\n",
      "episode: 2450/10000, score: 0.0, e: 0.009985630741373389, reward: [9.88793198]\n",
      "episode: 2450/10000, score: 0.0, e: 0.009985630741373389, reward: [9.88793198]\n",
      "episode: 2500/10000, score: 0.02, e: 0.009985630741373389, reward: [8.98584731]\n",
      "episode: 2500/10000, score: 0.02, e: 0.009985630741373389, reward: [8.98584731]\n",
      "episode: 2550/10000, score: 0.16, e: 0.009985630741373389, reward: [10.11366374]\n",
      "episode: 2550/10000, score: 0.16, e: 0.009985630741373389, reward: [10.11366374]\n",
      "episode: 2600/10000, score: 0.22, e: 0.009985630741373389, reward: [9.77347058]\n",
      "episode: 2600/10000, score: 0.22, e: 0.009985630741373389, reward: [9.77347058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2650/10000, score: 0.18, e: 0.009985630741373389, reward: [9.2869665]\n",
      "episode: 2650/10000, score: 0.18, e: 0.009985630741373389, reward: [9.2869665]\n",
      "episode: 2700/10000, score: 0.0, e: 0.009985630741373389, reward: [9.49412788]\n",
      "episode: 2700/10000, score: 0.0, e: 0.009985630741373389, reward: [9.49412788]\n",
      "episode: 2750/10000, score: 0.0, e: 0.009985630741373389, reward: [9.19860784]\n",
      "episode: 2750/10000, score: 0.0, e: 0.009985630741373389, reward: [9.19860784]\n",
      "episode: 2800/10000, score: 0.06, e: 0.009985630741373389, reward: [8.68899838]\n",
      "episode: 2800/10000, score: 0.06, e: 0.009985630741373389, reward: [8.68899838]\n",
      "episode: 2850/10000, score: 0.0, e: 0.009985630741373389, reward: [9.80359259]\n",
      "episode: 2850/10000, score: 0.0, e: 0.009985630741373389, reward: [9.80359259]\n",
      "episode: 2900/10000, score: 0.0, e: 0.009985630741373389, reward: [9.07097216]\n",
      "episode: 2900/10000, score: 0.0, e: 0.009985630741373389, reward: [9.07097216]\n",
      "episode: 2950/10000, score: 0.0, e: 0.009985630741373389, reward: [0.97690516]\n",
      "episode: 2950/10000, score: 0.0, e: 0.009985630741373389, reward: [0.97690516]\n",
      "episode: 3000/10000, score: 0.32, e: 0.009985630741373389, reward: [9.94572466]\n",
      "episode: 3000/10000, score: 0.32, e: 0.009985630741373389, reward: [9.94572466]\n",
      "episode: 3050/10000, score: 0.04, e: 0.009985630741373389, reward: [9.65637737]\n",
      "episode: 3050/10000, score: 0.04, e: 0.009985630741373389, reward: [9.65637737]\n",
      "episode: 3100/10000, score: 0.1, e: 0.009985630741373389, reward: [9.12767464]\n",
      "episode: 3100/10000, score: 0.1, e: 0.009985630741373389, reward: [9.12767464]\n",
      "episode: 3150/10000, score: 0.02, e: 0.009985630741373389, reward: [8.63017166]\n",
      "episode: 3150/10000, score: 0.02, e: 0.009985630741373389, reward: [8.63017166]\n",
      "episode: 3200/10000, score: 0.0, e: 0.009985630741373389, reward: [8.92071758]\n",
      "episode: 3200/10000, score: 0.0, e: 0.009985630741373389, reward: [8.92071758]\n",
      "episode: 3250/10000, score: 0.1, e: 0.009985630741373389, reward: [9.31351004]\n",
      "episode: 3250/10000, score: 0.1, e: 0.009985630741373389, reward: [9.31351004]\n",
      "episode: 3300/10000, score: 0.08, e: 0.009985630741373389, reward: [9.71333107]\n",
      "episode: 3300/10000, score: 0.08, e: 0.009985630741373389, reward: [9.71333107]\n",
      "episode: 3350/10000, score: 0.12, e: 0.009985630741373389, reward: [9.16452615]\n",
      "episode: 3350/10000, score: 0.12, e: 0.009985630741373389, reward: [9.16452615]\n",
      "episode: 3400/10000, score: 0.42, e: 0.009985630741373389, reward: [10.49697348]\n",
      "episode: 3400/10000, score: 0.42, e: 0.009985630741373389, reward: [10.49697348]\n",
      "episode: 3450/10000, score: 0.0, e: 0.009985630741373389, reward: [9.61952078]\n",
      "episode: 3450/10000, score: 0.0, e: 0.009985630741373389, reward: [9.61952078]\n",
      "episode: 3500/10000, score: 0.0, e: 0.009985630741373389, reward: [8.86672227]\n",
      "episode: 3500/10000, score: 0.0, e: 0.009985630741373389, reward: [8.86672227]\n",
      "episode: 3550/10000, score: 0.0, e: 0.009985630741373389, reward: [8.42540285]\n",
      "episode: 3550/10000, score: 0.0, e: 0.009985630741373389, reward: [8.42540285]\n",
      "episode: 3600/10000, score: 0.0, e: 0.009985630741373389, reward: [8.71500854]\n",
      "episode: 3600/10000, score: 0.0, e: 0.009985630741373389, reward: [8.71500854]\n",
      "episode: 3650/10000, score: 0.2, e: 0.009985630741373389, reward: [8.95585318]\n",
      "episode: 3650/10000, score: 0.2, e: 0.009985630741373389, reward: [8.95585318]\n",
      "episode: 3700/10000, score: 0.0, e: 0.009985630741373389, reward: [7.23844481]\n",
      "episode: 3700/10000, score: 0.0, e: 0.009985630741373389, reward: [7.23844481]\n",
      "episode: 3750/10000, score: 0.12, e: 0.009985630741373389, reward: [8.68587236]\n",
      "episode: 3750/10000, score: 0.12, e: 0.009985630741373389, reward: [8.68587236]\n",
      "episode: 3800/10000, score: 0.0, e: 0.009985630741373389, reward: [9.86781703]\n",
      "episode: 3800/10000, score: 0.0, e: 0.009985630741373389, reward: [9.86781703]\n",
      "episode: 3850/10000, score: 0.14, e: 0.009985630741373389, reward: [9.70055588]\n",
      "episode: 3850/10000, score: 0.14, e: 0.009985630741373389, reward: [9.70055588]\n",
      "episode: 3900/10000, score: 0.0, e: 0.009985630741373389, reward: [9.46771279]\n",
      "episode: 3900/10000, score: 0.0, e: 0.009985630741373389, reward: [9.46771279]\n",
      "episode: 3950/10000, score: 0.0, e: 0.009985630741373389, reward: [7.88999707]\n",
      "episode: 3950/10000, score: 0.0, e: 0.009985630741373389, reward: [7.88999707]\n",
      "episode: 4000/10000, score: 0.0, e: 0.009985630741373389, reward: [8.85777164]\n",
      "episode: 4000/10000, score: 0.0, e: 0.009985630741373389, reward: [8.85777164]\n",
      "episode: 4050/10000, score: 0.0, e: 0.009985630741373389, reward: [9.89241172]\n",
      "episode: 4050/10000, score: 0.0, e: 0.009985630741373389, reward: [9.89241172]\n",
      "episode: 4100/10000, score: 0.38, e: 0.009985630741373389, reward: [8.73348152]\n",
      "episode: 4100/10000, score: 0.38, e: 0.009985630741373389, reward: [8.73348152]\n",
      "episode: 4150/10000, score: 0.38, e: 0.009985630741373389, reward: [10.35376645]\n",
      "episode: 4150/10000, score: 0.38, e: 0.009985630741373389, reward: [10.35376645]\n",
      "episode: 4200/10000, score: 0.1, e: 0.009985630741373389, reward: [8.33100616]\n",
      "episode: 4200/10000, score: 0.1, e: 0.009985630741373389, reward: [8.33100616]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6bc73398f8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mbreak\u001b[0m \u001b[0;31m# exit loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"weights_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{:04d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bc795eab8d23>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n\u001b[1;32m     59\u001b[0m                           np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# approximately map current state to future discounted reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;31m#print(\"state\", state, \"reward: \", reward, \"done \", done, \"predict \", self.model.predict(next_state)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6bc73398f8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mbreak\u001b[0m \u001b[0;31m# exit loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the agent by replaying the experiences of the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"weights_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{:04d}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bc795eab8d23>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n\u001b[1;32m     59\u001b[0m                           np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# approximately map current state to future discounted reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;31m#print(\"state\", state, \"reward: \", reward, \"done \", done, \"predict \", self.model.predict(next_state)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluatory stats\n",
    "optimal_action = 3\n",
    "correct_action = 0\n",
    "total_reward = 0\n",
    "all_rewards = []\n",
    "most_chosen_action =[]\n",
    "pcnt_opt =[]\n",
    "n_episodes = 10000\n",
    "batch_size = 32\n",
    "agent.epsilon = 1\n",
    "\n",
    "\n",
    "done = False\n",
    "\n",
    "for e in range(n_episodes): # iterate over new episodes of the game\n",
    "    state = env.reset() # reset state at start of each new episode of the game\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    \n",
    "    correct_action = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    # time represents a frame of the game; goal is to keep pole upright as\n",
    "    # long as possible up to range, e.g., 500 or 5000 timesteps:\n",
    "    for time in range(number_time_steps):  \n",
    "        action = agent.act(state)\n",
    "        # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position:\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward = reward if not done else 0 # reward +1 for each additional frame with pole upright        \n",
    "        next_state = np.reshape(next_state, [1, state_size]) \n",
    "        total_reward += reward\n",
    "        \n",
    "        # remember the previous timestep's state, actions, reward, etc.:\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        # set \"current state\" for upcoming iteration to the current next state:\n",
    "        state = next_state\n",
    "        \n",
    "        # Evaluation\n",
    "        if action == optimal_action:\n",
    "            correct_action += 1\n",
    "        if done: \n",
    "            percent_optimal = correct_action / number_time_steps\n",
    "            all_rewards.append(total_reward)\n",
    "            pcnt_opt.append(percent_optimal)\n",
    "            #print(\"episode: {}/{}, score: {}, e: {:.2}, reward: {:.2}\" # print the episode's score and agent's epsilon\n",
    "                  #.format(e, n_episodes, percent_optimal, agent.epsilon, total_reward))\n",
    "            break # exit loop\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size) # train the agent by replaying the experiences of the episode\n",
    "    if e % 50 == 0:\n",
    "        agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")\n",
    "        print(\"episode: {}/{}, score: {}, e: {}, reward: {}\" # print the episode's score and agent's epsilon\n",
    "                  .format(e, n_episodes, percent_optimal, agent.epsilon, total_reward))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x142fb2da0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x142fb2da0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-b2118b4be176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_rewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.plot([0, 5000], [9.5, 9.5], 'k-')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "plt.plot(moving_average(all_rewards,200))\n",
    "#plt.plot([0, 5000], [9.5, 9.5], 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(moving_average(pcnt_opt,600))\n",
    "#plt.plot([0, 5000], [twap_stat, twap_stat], 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, agent_name):\n",
    "        self.agent_name = agent_name\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        # double-ended queue; acts like list, but elements can be added/removed from either end:\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        # decay or discount rate: enables agent to take into account future actions in addition\n",
    "        # to the immediate ones, but discounted at this rate:\n",
    "        self.gamma = 1 # Was 0.95\n",
    "        # exploration rate: how much to act randomly; more initially than later due to epsilon\n",
    "        # decay:\n",
    "        self.epsilon = 1.0\n",
    "        # decrease number of random explorations as the agent's performance (hopefully)\n",
    "        # improves over time:\n",
    "        self.epsilon_decay = 0.998 \n",
    "        # minimum amount of random exploration permitted:\n",
    "        self.epsilon_min = 0.01\n",
    "        # rate at which NN adjusts models parameters via SGD to reduce cost:\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(5, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(5, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # list of previous experiences, enabling re-training later\n",
    "        #print(\"State \", state, \"Action \", action, \"Reward \", reward, \"next state \", next_state, \"done\", done)\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # if acting randomly, take random action:\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        # if not acting randomly, predict reward value based on current state:\n",
    "        act_values = self.model.predict(state)\n",
    "        # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    # method that trains NN with experiences sampled from memory:\n",
    "    def replay(self, batch_size):\n",
    "        # sample a minibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        # extract data for each minibatch sample:\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward:\n",
    "            target = reward\n",
    "\n",
    "            # if not done, then predict future discounted reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            #print(\"state\", state, \"reward: \", reward, \"done \", done, \"predict \", self.model.predict(next_state)[0])\n",
    "            target_f[0][action] = target\n",
    "            # Change the action taken to the reward + predicted max of next states\n",
    "            # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat:\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, file_name):\n",
    "        self.model.load_weights(file_name)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.model.save_weights(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
